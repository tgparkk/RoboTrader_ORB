#!/usr/bin/env python3
"""
íŒ¨í„´ ë°ì´í„° ë¡œê·¸ì—ì„œ ML í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±

ì…ë ¥: pattern_data_log/*.jsonl
ì¶œë ¥: ml_dataset.csv (í•™ìŠµìš© í”¼ì²˜ + ë¼ë²¨)
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import numpy as np


def safe_float_from_percent(value, default=0.0):
    """í¼ì„¼íŠ¸ ë¬¸ìì—´ ë˜ëŠ” ìˆ«ìë¥¼ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        return float(value.replace('%', ''))
    return default


def safe_int_from_str(value, default=0):
    """ë¬¸ìì—´ì´ë‚˜ ìˆ«ìë¥¼ intë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if value is None:
        return default
    try:
        return int(float(str(value).replace(',', '')))
    except:
        return default


def extract_features_from_pattern(pattern_data: Dict) -> Optional[Dict]:
    """íŒ¨í„´ ë°ì´í„°ì—ì„œ ML íŠ¹ì§•(feature) ì¶”ì¶œ

    Returns:
        Dict: íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None (ë§¤ë§¤ê²°ê³¼ ì—†ëŠ” ê²½ìš°)
    """
    # ë§¤ë§¤ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ë¼ë²¨ì´ ì—†ìŒ)
    trade_result = pattern_data.get('trade_result')
    if trade_result is None or not trade_result.get('trade_executed', False):
        return None

    # ë¼ë²¨ (ìŠ¹/íŒ¨)
    profit_rate = trade_result.get('profit_rate', 0)
    label = 1 if profit_rate > 0 else 0  # 1=ìŠ¹ë¦¬, 0=íŒ¨ë°°

    # ê¸°ë³¸ ì •ë³´
    signal_info = pattern_data.get('signal_info', {})
    pattern_stages = pattern_data.get('pattern_stages', {})

    # íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
    timestamp_str = pattern_data.get('timestamp', '')
    try:
        dt = datetime.fromisoformat(timestamp_str)
        hour = dt.hour
        minute = dt.minute
        time_in_minutes = hour * 60 + minute  # 9:00 = 540, 15:30 = 930
    except:
        hour = 0
        minute = 0
        time_in_minutes = 0

    # === ì‹ í˜¸ íŠ¹ì§• ===
    signal_type = signal_info.get('signal_type', 'UNKNOWN')
    confidence = signal_info.get('confidence', 0)

    # === íŒ¨í„´ íŠ¹ì§• ===
    # 1ë‹¨ê³„: ìƒìŠ¹êµ¬ê°„
    uptrend = pattern_stages.get('1_uptrend', {})
    uptrend_candles = uptrend.get('candle_count', 0)
    uptrend_gain = safe_float_from_percent(uptrend.get('price_gain', '0%'))
    uptrend_max_volume = safe_int_from_str(uptrend.get('max_volume', '0'))

    # ìƒìŠ¹êµ¬ê°„ ìº”ë“¤ ë°ì´í„°ì—ì„œ ì¶”ê°€ íŠ¹ì§•
    uptrend_candles_data = uptrend.get('candles', [])
    if uptrend_candles_data:
        uptrend_avg_body = np.mean([abs(c['close'] - c['open']) for c in uptrend_candles_data])
        uptrend_total_volume = sum([c['volume'] for c in uptrend_candles_data])
    else:
        uptrend_avg_body = 0
        uptrend_total_volume = 0

    # 2ë‹¨ê³„: í•˜ë½êµ¬ê°„
    decline = pattern_stages.get('2_decline', {})
    decline_candles = decline.get('candle_count', 0)
    decline_pct = safe_float_from_percent(decline.get('decline_pct', '0%'))

    decline_candles_data = decline.get('candles', [])
    if decline_candles_data:
        decline_avg_volume = np.mean([c['volume'] for c in decline_candles_data])
    else:
        decline_avg_volume = 0

    # 3ë‹¨ê³„: ì§€ì§€êµ¬ê°„
    support = pattern_stages.get('3_support', {})
    support_candles = support.get('candle_count', 0)
    support_volatility = safe_float_from_percent(support.get('price_volatility', '0%'))
    support_avg_volume_ratio = safe_float_from_percent(support.get('avg_volume_ratio', '0%'))

    support_candles_data = support.get('candles', [])
    if support_candles_data:
        support_avg_volume = np.mean([c['volume'] for c in support_candles_data])
    else:
        support_avg_volume = 0

    # 4ë‹¨ê³„: ëŒíŒŒì–‘ë´‰
    breakout = pattern_stages.get('4_breakout', {})
    breakout_candle = breakout.get('candle', {})
    if breakout_candle:
        breakout_volume = breakout_candle.get('volume', 0)
        breakout_body = abs(breakout_candle.get('close', 0) - breakout_candle.get('open', 0))
        breakout_high = breakout_candle.get('high', 0)
        breakout_low = breakout_candle.get('low', 0)
        breakout_range = breakout_high - breakout_low
    else:
        breakout_volume = 0
        breakout_body = 0
        breakout_range = 0

    # === íŒŒìƒ íŠ¹ì§• ===
    # ê±°ë˜ëŸ‰ ë¹„ìœ¨
    volume_ratio_decline_to_uptrend = (decline_avg_volume / uptrend_max_volume) if uptrend_max_volume > 0 else 0
    volume_ratio_support_to_uptrend = (support_avg_volume / uptrend_max_volume) if uptrend_max_volume > 0 else 0
    volume_ratio_breakout_to_uptrend = (breakout_volume / uptrend_max_volume) if uptrend_max_volume > 0 else 0

    # ê°€ê²© ë³€ë™ ë¹„ìœ¨
    price_gain_to_decline_ratio = (uptrend_gain / abs(decline_pct)) if decline_pct != 0 else 0

    # ìº”ë“¤ ê°œìˆ˜ ë¹„ìœ¨
    candle_ratio_support_to_decline = (support_candles / decline_candles) if decline_candles > 0 else 0

    features = {
        # ë¼ë²¨
        'label': label,
        'profit_rate': profit_rate,
        'sell_reason': trade_result.get('sell_reason', ''),

        # ì‹œê°„ íŠ¹ì§•
        'hour': hour,
        'minute': minute,
        'time_in_minutes': time_in_minutes,
        'is_morning': 1 if hour < 12 else 0,

        # ì‹ í˜¸ íŠ¹ì§•
        'signal_type': signal_type,
        'confidence': confidence,

        # íŒ¨í„´ íŠ¹ì§• - ìƒìŠ¹êµ¬ê°„
        'uptrend_candles': uptrend_candles,
        'uptrend_gain': uptrend_gain,
        'uptrend_max_volume': uptrend_max_volume,
        'uptrend_avg_body': uptrend_avg_body,
        'uptrend_total_volume': uptrend_total_volume,

        # íŒ¨í„´ íŠ¹ì§• - í•˜ë½êµ¬ê°„
        'decline_candles': decline_candles,
        'decline_pct': abs(decline_pct),  # ì ˆëŒ“ê°’
        'decline_avg_volume': decline_avg_volume,

        # íŒ¨í„´ íŠ¹ì§• - ì§€ì§€êµ¬ê°„
        'support_candles': support_candles,
        'support_volatility': support_volatility,
        'support_avg_volume_ratio': support_avg_volume_ratio,
        'support_avg_volume': support_avg_volume,

        # íŒ¨í„´ íŠ¹ì§• - ëŒíŒŒì–‘ë´‰
        'breakout_volume': breakout_volume,
        'breakout_body': breakout_body,
        'breakout_range': breakout_range,

        # íŒŒìƒ íŠ¹ì§•
        'volume_ratio_decline_to_uptrend': volume_ratio_decline_to_uptrend,
        'volume_ratio_support_to_uptrend': volume_ratio_support_to_uptrend,
        'volume_ratio_breakout_to_uptrend': volume_ratio_breakout_to_uptrend,
        'price_gain_to_decline_ratio': price_gain_to_decline_ratio,
        'candle_ratio_support_to_decline': candle_ratio_support_to_decline,

        # ë©”íƒ€ë°ì´í„°
        'stock_code': pattern_data.get('stock_code', ''),
        'pattern_id': pattern_data.get('pattern_id', ''),
        'timestamp': timestamp_str,
    }

    return features


def load_all_pattern_data(pattern_log_dir: Path) -> List[Dict]:
    """ëª¨ë“  íŒ¨í„´ ë¡œê·¸ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    all_patterns = []

    jsonl_files = sorted(pattern_log_dir.glob('pattern_data_*.jsonl'))

    print(f"ğŸ“‚ íŒ¨í„´ ë¡œê·¸ íŒŒì¼ {len(jsonl_files)}ê°œ ë°œê²¬")

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        pattern = json.loads(line)
                        all_patterns.append(pattern)
        except Exception as e:
            print(f"âš ï¸ {jsonl_file.name} ë¡œë“œ ì˜¤ë¥˜: {e}")

    print(f"ğŸ“Š ì´ {len(all_patterns)}ê°œ íŒ¨í„´ ë¡œë“œ ì™„ë£Œ")
    return all_patterns


def create_ml_dataset(pattern_log_dir: str = 'pattern_data_log', output_file: str = 'ml_dataset.csv'):
    """ML ë°ì´í„°ì…‹ ìƒì„±"""
    import sys
    sys.stdout.reconfigure(encoding='utf-8')

    print("=" * 70)
    print("ğŸ¤– ML í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
    print("=" * 70)

    # íŒ¨í„´ ë°ì´í„° ë¡œë“œ
    pattern_log_path = Path(pattern_log_dir)
    if not pattern_log_path.exists():
        print(f"âŒ íŒ¨í„´ ë¡œê·¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pattern_log_dir}")
        return

    all_patterns = load_all_pattern_data(pattern_log_path)

    # íŠ¹ì§• ì¶”ì¶œ
    print("\nğŸ”§ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    features_list = []

    for i, pattern in enumerate(all_patterns):
        if (i + 1) % 100 == 0:
            print(f"   ì²˜ë¦¬ ì¤‘... {i+1}/{len(all_patterns)}")

        features = extract_features_from_pattern(pattern)
        if features is not None:
            features_list.append(features)

    if not features_list:
        print("âŒ ë§¤ë§¤ ê²°ê³¼ê°€ ìˆëŠ” íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # DataFrame ìƒì„±
    df = pd.DataFrame(features_list)

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ“Š ë°ì´í„°ì…‹ í†µê³„")
    print("=" * 70)
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(df)}")
    print(f"ìŠ¹ë¦¬ ìƒ˜í”Œ: {df['label'].sum()} ({df['label'].mean()*100:.1f}%)")
    print(f"íŒ¨ë°° ìƒ˜í”Œ: {len(df) - df['label'].sum()} ({(1-df['label'].mean())*100:.1f}%)")
    print(f"\níŠ¹ì§•(feature) ìˆ˜: {len(df.columns) - 5}")  # ë¼ë²¨ ê´€ë ¨ ì»¬ëŸ¼ ì œì™¸

    # ì‹œê°„ëŒ€ë³„ í†µê³„
    print("\nâ° ì‹œê°„ëŒ€ë³„ ë¶„í¬:")
    for hour in sorted(df['hour'].unique()):
        hour_df = df[df['hour'] == hour]
        win_rate = hour_df['label'].mean() * 100
        print(f"   {hour:02d}ì‹œ: {len(hour_df):3d}ê±´ (ìŠ¹ë¥  {win_rate:.1f}%)")

    # ì‹ í˜¸ íƒ€ì…ë³„ í†µê³„
    print("\nğŸ¯ ì‹ í˜¸ íƒ€ì…ë³„ ë¶„í¬:")
    for signal_type in df['signal_type'].unique():
        sig_df = df[df['signal_type'] == signal_type]
        win_rate = sig_df['label'].mean() * 100
        print(f"   {signal_type}: {len(sig_df):3d}ê±´ (ìŠ¹ë¥  {win_rate:.1f}%)")

    # CSV ì €ì¥
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {output_file}")
    print(f"   íŒŒì¼ í¬ê¸°: {Path(output_file).stat().st_size / 1024:.1f} KB")

    # ì»¬ëŸ¼ ëª©ë¡ ì¶œë ¥
    print("\nğŸ“‹ íŠ¹ì§•(feature) ì»¬ëŸ¼ ëª©ë¡:")
    feature_cols = [col for col in df.columns if col not in ['label', 'profit_rate', 'sell_reason', 'stock_code', 'pattern_id', 'timestamp']]
    for i, col in enumerate(feature_cols, 1):
        print(f"   {i:2d}. {col}")

    return df


if __name__ == '__main__':
    df = create_ml_dataset()

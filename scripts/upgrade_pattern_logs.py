#!/usr/bin/env python3
"""
ê¸°ì¡´ íŒ¨í„´ ë¡œê·¸ë¥¼ ì‹ ê·œ í˜•ì‹ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

ì¶”ê°€í•  ì •ë³´:
1. signal_time (pattern_idì—ì„œ ì¶”ì¶œ)
2. log_timestamp (ê¸°ì¡´ timestampë¥¼ ì‚¬ìš©)
3. signal_snapshot (1ë¶„ë´‰ ë°ì´í„°ë¡œë¶€í„° ê³„ì‚°)
   - technical_indicators_3min/1min
   - lookback_sequence_1min
4. post_trade_analysis (ë§¤ë§¤ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

import json
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
from typing import Dict, Any, Optional

try:
    from tqdm import tqdm as tqdm_func
except ImportError:
    # tqdmì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë°˜ë³µì ì‚¬ìš©
    def tqdm_func(iterable, desc=""):
        return iterable

# íŒ¨í„´ ë¡œê±° ì„í¬íŠ¸ (ê¸°ìˆ  ì§€í‘œ ê³„ì‚° ë¡œì§ ì¬ì‚¬ìš©)
from core.pattern_data_logger import PatternDataLogger


def extract_signal_time_from_pattern_id(pattern_id: str) -> Optional[datetime]:
    """
    pattern_idì—ì„œ signal_time ì¶”ì¶œ
    í˜•ì‹: {stock_code}_{YYYYMMDD}_{HHMMSS}
    ì˜ˆ: 347850_20251105_191023
    """
    try:
        parts = pattern_id.split('_')
        if len(parts) >= 3:
            date_str = parts[1]  # 20251105
            time_str = parts[2]  # 191023

            datetime_str = f"{date_str}_{time_str}"
            return datetime.strptime(datetime_str, '%Y%m%d_%H%M%S')
    except Exception as e:
        print(f"âš ï¸ pattern_id íŒŒì‹± ì‹¤íŒ¨ ({pattern_id}): {e}")

    return None


def load_minute_data(stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
    """1ë¶„ë´‰ ë°ì´í„° ë¡œë“œ"""
    try:
        cache_file = Path(f'cache/minute_data/{stock_code}_{date_str}.pkl')
        if cache_file.exists():
            df = pd.read_pickle(cache_file)
            # datetime ì»¬ëŸ¼ í™•ì¸
            if 'datetime' not in df.columns and 'time' in df.columns:
                df['datetime'] = pd.to_datetime(df['time'])
            return df
    except Exception as e:
        print(f"âš ï¸ {stock_code} 1ë¶„ë´‰ ë¡œë“œ ì‹¤íŒ¨: {e}")

    return None


def upgrade_pattern_log(log_file: Path, dry_run: bool = False) -> Dict[str, int]:
    """
    íŒ¨í„´ ë¡œê·¸ íŒŒì¼ì„ ì‹ ê·œ í˜•ì‹ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

    Args:
        log_file: ì—…ê·¸ë ˆì´ë“œí•  ë¡œê·¸ íŒŒì¼
        dry_run: Trueì´ë©´ ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸í•˜ê³  ì‹¤ì œ ì“°ê¸°ëŠ” ì•ˆí•¨

    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    stats = {
        'total': 0,
        'upgraded': 0,
        'failed': 0,
        'skipped': 0
    }

    print(f"\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {log_file.name}")

    # ë¡œê·¸ ì½ê¸°
    records = []
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    record = json.loads(line)
                    records.append(record)
                    stats['total'] += 1
                except Exception as e:
                    print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    stats['failed'] += 1

    print(f"  ì´ {stats['total']}ê°œ íŒ¨í„´ ë¡œë“œë¨")

    # íŒ¨í„´ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ (ê¸°ìˆ  ì§€í‘œ ê³„ì‚°ìš©)
    date_str = log_file.stem.replace('pattern_data_', '')
    pattern_logger = PatternDataLogger()

    # ê° ë ˆì½”ë“œ ì—…ê·¸ë ˆì´ë“œ
    for i, record in enumerate(tqdm_func(records, desc="  ì—…ê·¸ë ˆì´ë“œ")):
        try:
            # ì´ë¯¸ ì—…ê·¸ë ˆì´ë“œëœ ê²½ìš° ìŠ¤í‚µ
            if 'signal_time' in record and 'signal_snapshot' in record:
                stats['skipped'] += 1
                continue

            # 1. signal_time ì¶”ì¶œ
            pattern_id = record.get('pattern_id', '')
            signal_time = extract_signal_time_from_pattern_id(pattern_id)

            if not signal_time:
                stats['failed'] += 1
                continue

            # 2. log_timestamp ì„¤ì • (ê¸°ì¡´ timestamp ì‚¬ìš©)
            log_timestamp = record.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

            # 3. 1ë¶„ë´‰ ë°ì´í„° ë¡œë“œ
            stock_code = record.get('stock_code', '')
            df_1min = load_minute_data(stock_code, signal_time.strftime('%Y%m%d'))

            # 4. signal_snapshot ê³„ì‚°
            signal_snapshot = {
                'technical_indicators_3min': {},
                'technical_indicators_1min': {},
                'lookback_sequence_1min': []
            }

            if df_1min is not None and not df_1min.empty:
                # 1ë¶„ë´‰ì—ì„œ ì‹ í˜¸ ì‹œì  ì°¾ê¸°
                signal_1min_data = df_1min[df_1min['datetime'] <= signal_time]
                if not signal_1min_data.empty:
                    signal_1min_idx = len(signal_1min_data) - 1

                    # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                    signal_snapshot['technical_indicators_1min'] = pattern_logger._calculate_technical_indicators(
                        df_1min, signal_1min_idx
                    )

                    # Lookback ì‹œí€€ìŠ¤
                    signal_snapshot['lookback_sequence_1min'] = pattern_logger._extract_lookback_sequence(
                        df_1min, signal_time, lookback_minutes=60
                    )

            # 5. post_trade_analysis ê³„ì‚° (ë§¤ë§¤ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
            trade_result = record.get('trade_result')
            if trade_result and trade_result.get('trade_executed') and df_1min is not None:
                # ë§¤ìˆ˜ ì‹œê° = signal_time
                # ë§¤ë„ ì‹œê°ì€ ì¶”ì • ë¶ˆê°€ëŠ¥ (ê¸°ì¡´ ë¡œê·¸ì— ì—†ìŒ) - íŒ¨ìŠ¤
                pass

            # 6. ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
            record['signal_time'] = signal_time.strftime('%Y-%m-%d %H:%M:%S')
            record['log_timestamp'] = log_timestamp
            record['signal_snapshot'] = signal_snapshot

            # timestamp í•„ë“œëŠ” ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)

            stats['upgraded'] += 1

        except Exception as e:
            print(f"âš ï¸ ë ˆì½”ë“œ {i} ì—…ê·¸ë ˆì´ë“œ ì‹¤íŒ¨: {e}")
            stats['failed'] += 1

    # 7. íŒŒì¼ ì“°ê¸° (dry_runì´ ì•„ë‹Œ ê²½ìš°)
    if not dry_run and stats['upgraded'] > 0:
        backup_file = log_file.with_suffix('.jsonl.backup')

        # ë°±ì—… (ì´ë¯¸ ìˆìœ¼ë©´ ì‚­ì œ)
        if backup_file.exists():
            backup_file.unlink()
        log_file.rename(backup_file)
        print(f"  âœ… ë°±ì—… ìƒì„±: {backup_file.name}")

        # ìƒˆ íŒŒì¼ ì“°ê¸°
        with open(log_file, 'w', encoding='utf-8') as f:
            for record in records:
                json_str = json.dumps(record, ensure_ascii=False)
                f.write(json_str + '\n')

        print(f"  âœ… ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ: {stats['upgraded']}ê°œ")

    return stats


def main():
    print("=" * 70)
    print("ğŸ”„ íŒ¨í„´ ë¡œê·¸ ì—…ê·¸ë ˆì´ë“œ")
    print("=" * 70)

    log_dir = Path('pattern_data_log')
    log_files = sorted(log_dir.glob('pattern_data_2025*.jsonl'))

    print(f"\nğŸ“Š ì´ {len(log_files)}ê°œ íŒŒì¼ ë°œê²¬")

    # Dry runìœ¼ë¡œ ë¨¼ì € í™•ì¸
    print("\n=== Dry Run (ë³€ê²½ì‚¬í•­ í™•ì¸) ===")
    total_stats = {'total': 0, 'upgraded': 0, 'failed': 0, 'skipped': 0}

    for log_file in log_files[:3]:  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
        stats = upgrade_pattern_log(log_file, dry_run=True)
        for key in total_stats:
            total_stats[key] += stats[key]

    print("\n=== Dry Run ê²°ê³¼ ===")
    print(f"ì´ íŒ¨í„´: {total_stats['total']}")
    print(f"ì—…ê·¸ë ˆì´ë“œ í•„ìš”: {total_stats['upgraded']}")
    print(f"ì´ë¯¸ ì™„ë£Œ: {total_stats['skipped']}")
    print(f"ì‹¤íŒ¨: {total_stats['failed']}")

    if total_stats['upgraded'] == 0:
        print("\nì—…ê·¸ë ˆì´ë“œí•  íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nìë™ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")

    print("\n=== ì‹¤ì œ ì—…ê·¸ë ˆì´ë“œ ì‹œì‘ ===")
    total_stats = {'total': 0, 'upgraded': 0, 'failed': 0, 'skipped': 0}

    for log_file in log_files:
        stats = upgrade_pattern_log(log_file, dry_run=False)
        for key in total_stats:
            total_stats[key] += stats[key]

    print("\n" + "=" * 70)
    print("âœ… ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ")
    print("=" * 70)
    print(f"ì´ íŒ¨í„´: {total_stats['total']}")
    print(f"ì—…ê·¸ë ˆì´ë“œ: {total_stats['upgraded']}")
    print(f"ì´ë¯¸ ì™„ë£Œ: {total_stats['skipped']}")
    print(f"ì‹¤íŒ¨: {total_stats['failed']}")


if __name__ == '__main__':
    main()

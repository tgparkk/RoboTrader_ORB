"""
ë°ì´í„° ì²˜ë¦¬ ë° ì§€í‘œ ê³„ì‚° ì „ìš© í´ë˜ìŠ¤
"""
import asyncio
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from typing import Optional, Dict, List, Any
from utils.logger import setup_logger
from api.kis_chart_api import get_inquire_time_dailychartprice, get_div_code_for_stock, get_stock_data_with_fallback
from core.indicators.price_box import PriceBox
from core.indicators.bisector_line import BisectorLine
from core.indicators.bollinger_bands import BollingerBands
from core.indicators.multi_bollinger_bands import MultiBollingerBands


def get_stock_data_fixed_market(stock_code: str, input_date: str, input_hour: str, past_data_yn: str = "Y", div_code: str = "J") -> Optional[tuple]:
    """
    ê³ ì •ëœ ì‹œì¥ìœ¼ë¡œ ì¢…ëª© ë°ì´í„° ì¡°íšŒ
    
    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        input_date: ì…ë ¥ ë‚ ì§œ (YYYYMMDD)
        input_hour: ì…ë ¥ ì‹œê°„ (HHMMSS)
        past_data_yn: ê³¼ê±° ë°ì´í„° í¬í•¨ ì—¬ë¶€
        div_code: ì‹œì¥ êµ¬ë¶„ ì½”ë“œ (J: KRX, NX: NXT ë“±)
        
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: (ì¢…ëª©ìš”ì•½ì •ë³´, ë¶„ë´‰ë°ì´í„°) ë˜ëŠ” None
    """
    try:
        result = get_inquire_time_dailychartprice(
            div_code=div_code,
            stock_code=stock_code,
            input_date=input_date,
            input_hour=input_hour,
            past_data_yn=past_data_yn
        )
        return result
    except Exception as e:
        print(f"âŒ {stock_code} {div_code} ì‹œì¥ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ ë° ì§€í‘œ ê³„ì‚° ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.logger = setup_logger(__name__)
        self.logger.info("ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _get_uniform_1min_close(self, data: pd.DataFrame) -> Optional[pd.Series]:
        """
        1ë¶„ ê°„ê²©ì´ ëˆ„ë½ë˜ì§€ ì•Šì€ ê· ì¼í•œ close ì‹œë¦¬ì¦ˆ ìƒì„± (FFILL)
        - 09:00 ~ 15:30 ë²”ìœ„ë¡œ ê³ ì •
        - ì¼ë¶€ ë¶„ ëˆ„ë½ ì‹œ ì´ì „ ê°’ìœ¼ë¡œ ë³´ê°„í•˜ì—¬ ë¡¤ë§ ì°½ ê¸¸ì´ ì™œê³¡ ìµœì†Œí™”
        """
        try:
            if data is None or data.empty:
                return None
            df = data.copy()
            # datetime í™•ë³´
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime'])
                base_date = df['datetime'].iloc[0].date()
            elif 'time' in df.columns:
                t = df['time'].astype(str).str.zfill(6)
                # ì„ì˜ ê¸°ì¤€ì¼ ì‚¬ìš© (ë™ì¼ ì¼ì ë‚´ì—ì„œ ìƒëŒ€ì  ë¶„ì‚°ë§Œ ì¤‘ìš”)
                base_date = pd.Timestamp.now().date()
                df['datetime'] = pd.to_datetime(
                    pd.Series([f"{base_date} {h}:{m}:{s}" for h, m, s in zip(t.str[:2], t.str[2:4], t.str[4:6])])
                )
            else:
                return None
            # 08:00 ~ 15:30 ê·¸ë¦¬ë“œ ìƒì„±
            start_dt = pd.Timestamp.combine(pd.Timestamp(base_date), pd.Timestamp('08:00').time())
            end_dt = pd.Timestamp.combine(pd.Timestamp(base_date), pd.Timestamp('15:30').time())
            full_index = pd.date_range(start=start_dt, end=end_dt, freq='T')
            # close ì‹œë¦¬ì¦ˆë¥¼ 1ë¶„ ê·¸ë¦¬ë“œì— ë§µí•‘
            close_series = pd.to_numeric(df.set_index('datetime')['close'], errors='coerce').sort_index()
            # ë™ì¼ ì¼ì ë²”ìœ„ë¡œ ìŠ¬ë¼ì´ìŠ¤ í›„ ë¦¬ì¸ë±ìŠ¤
            close_series = close_series.reindex(full_index).ffill().bfill()
            return close_series
        except Exception as e:
            self.logger.error(f"ê· ì¼ 1ë¶„ close ì‹œë¦¬ì¦ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def _reindex_price_box_to_data(self, box_result: Dict[str, pd.Series], data: pd.DataFrame) -> Dict[str, pd.Series]:
        """
        ê°€ê²©ë°•ìŠ¤ ê²°ê³¼(ê· ì¼ 1ë¶„ DateTimeIndex)ë¥¼ ì‹¤ì œ ë°ì´í„° ì¸ë±ìŠ¤ì— ë§ì¶° ì¬ìƒ‰ì¸
        - ë°ì´í„°ê°€ datetimeì„ í¬í•¨í•˜ë©´ ê·¸ íƒ€ì„ìŠ¤íƒ¬í”„ì— ë§ì¶° reindex + ffill
        - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸¸ì´ë§Œ ë§ì¶¤(ê¸°ì¡´ ì¸ë±ìŠ¤ ìœ ì§€)
        """
        try:
            if not box_result or 'center_line' not in box_result:
                return box_result
            if 'datetime' in data.columns:
                target_ts = pd.to_datetime(data['datetime']).sort_values()
                aligned = {}
                for key, series in box_result.items():
                    try:
                        s = series.reindex(target_ts, method='ffill').reset_index(drop=True)
                    except Exception:
                        s = series
                    aligned[key] = s
                return aligned
            else:
                return box_result
        except Exception as e:
            self.logger.error(f"ê°€ê²©ë°•ìŠ¤ ì¬ìƒ‰ì¸ ì˜¤ë¥˜: {e}")
            return box_result
    
    async def get_historical_chart_data(self, stock_code: str, target_date: str) -> Optional[pd.DataFrame]:
        """
        íŠ¹ì • ë‚ ì§œì˜ ì „ì²´ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ (ë¶„í•  ì¡°íšŒë¡œ ì „ì²´ ê±°ë˜ì‹œê°„ ì»¤ë²„)
        
        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            target_date: ì¡°íšŒ ë‚ ì§œ (YYYYMMDD)
            
        Returns:
            pd.DataFrame: ì „ì²´ ê±°ë˜ì‹œê°„ ë¶„ë´‰ ë°ì´í„° (09:00~15:30)
        """
        try:
            self.logger.info(f"{stock_code} {target_date} ì „ì²´ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì‹œì‘")
            
            # ë¶„í•  ì¡°íšŒë¡œ ì „ì²´ ê±°ë˜ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
            all_data = []
            
            # 15:30ë¶€í„° ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©´ì„œ ì¡°íšŒ (APIëŠ” ìµœì‹  ë°ì´í„°ë¶€í„° ì œê³µ)
            # 1íšŒ í˜¸ì¶œë‹¹ ìµœëŒ€ 120ë¶„ ë°ì´í„° â†’ 4ë²ˆ í˜¸ì¶œë¡œ ì „ì²´ ì»¤ë²„ (390ë¶„: 09:00~15:30)
            time_points = ["153000", "143000", "123000", "103000", "090000"]  # 15:30, 14:30, 12:30, 10:30, 09:00
            
            for i, end_time in enumerate(time_points):
                try:
                    self.logger.info(f"{stock_code} ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ {i+1}/5: {end_time[:2]}:{end_time[2:4]}ê¹Œì§€")
                    # KRX J ì‹œì¥ë§Œ ì¡°íšŒ
                    result = await asyncio.to_thread(
                        get_stock_data_fixed_market,
                        stock_code=stock_code,
                        input_date=target_date,
                        input_hour=end_time,
                        past_data_yn="Y",
                        div_code="J"
                    )
                    
                    if result is None:
                        self.logger.warning(f"{stock_code} {end_time} ì‹œì  ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
                        continue
                    
                    summary_df, chart_df = result
                    
                    if chart_df.empty:
                        self.logger.warning(f"{stock_code} {end_time} ì‹œì  ë¶„ë´‰ ë°ì´í„° ì—†ìŒ")
                        continue
                    
                    # ë°ì´í„° ê²€ì¦
                    required_columns = ['open', 'high', 'low', 'close', 'volume']
                    missing_columns = [col for col in required_columns if col not in chart_df.columns]
                    
                    if missing_columns:
                        self.logger.warning(f"{stock_code} {end_time} í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
                        continue
                    
                    # ìˆ«ì ë°ì´í„° íƒ€ì… ë³€í™˜
                    for col in required_columns:
                        chart_df[col] = pd.to_numeric(chart_df[col], errors='coerce')
                    
                    # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
                    chart_df = chart_df.dropna(subset=required_columns)
                    
                    if not chart_df.empty:
                        # ì‹œê°„ ë²”ìœ„ ì •ë³´ ì¶”ê°€ ë¡œê¹…
                        if 'time' in chart_df.columns:
                            time_col = 'time'
                        elif 'datetime' in chart_df.columns:
                            time_col = 'datetime'
                        else:
                            time_col = None
                            
                        if time_col:
                            first_time = chart_df[time_col].iloc[0]
                            last_time = chart_df[time_col].iloc[-1]
                            self.logger.info(f"{stock_code} {end_time} ì‹œì  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(chart_df)}ê±´ ({first_time} ~ {last_time})")
                            
                        else:
                            self.logger.info(f"{stock_code} {end_time} ì‹œì  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(chart_df)}ê±´")
                            
                        all_data.append(chart_df)
                    
                    # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    self.logger.error(f"{stock_code} {end_time} ì‹œì  ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            # ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„° ê²°í•©
            if not all_data:
                self.logger.error(f"{stock_code} {target_date} ëª¨ë“  ì‹œê°„ëŒ€ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
                return None
            
            # ë°ì´í„°í”„ë ˆì„ ê²°í•© ë° ì •ë ¬
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # ì‹œê°„ìˆœ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ)
            if 'datetime' in combined_df.columns:
                combined_df = combined_df.sort_values('datetime').reset_index(drop=True)
            elif 'time' in combined_df.columns:
                combined_df = combined_df.sort_values('time').reset_index(drop=True)
            
            # ì¤‘ë³µ ë°ì´í„° ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
            before_count = len(combined_df)
            if 'datetime' in combined_df.columns:
                combined_df = combined_df.drop_duplicates(subset=['datetime'], keep='last')
            elif 'time' in combined_df.columns:
                combined_df = combined_df.drop_duplicates(subset=['time'], keep='last')
            
            # ì¤‘ë³µ ì œê±° í›„ ë‹¤ì‹œ ì‹œê°„ìˆœ ì •ë ¬ (ì¤‘ìš”!)
            if 'datetime' in combined_df.columns:
                combined_df = combined_df.sort_values('datetime').reset_index(drop=True)
            elif 'time' in combined_df.columns:
                combined_df = combined_df.sort_values('time').reset_index(drop=True)
            
            after_count = len(combined_df)
            if before_count != after_count:
                self.logger.warning(f"ì¤‘ë³µ ì‹œê°„ ë°ì´í„° ì œê±°: {before_count} â†’ {after_count}")
            
            # íƒ€ê²Ÿ ë‚ ì§œ ë°ì´í„°ë§Œ í•„í„°ë§ (ì „ë‚  ë°ì´í„° ì œê±°)
            before_filter_count = len(combined_df)
            if 'datetime' in combined_df.columns:
                # datetime ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° ë‚ ì§œ í•„í„°ë§
                combined_df['date_str'] = pd.to_datetime(combined_df['datetime']).dt.strftime('%Y%m%d')
                combined_df = combined_df[combined_df['date_str'] == target_date].drop('date_str', axis=1)
            elif 'time' in combined_df.columns:
                # time ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° (YYYYMMDDHHMM í˜•ì‹)
                combined_df['date_str'] = combined_df['time'].astype(str).str[:8]
                combined_df = combined_df[combined_df['date_str'] == target_date].drop('date_str', axis=1)
            
            after_filter_count = len(combined_df)
            if before_filter_count != after_filter_count:
                self.logger.info(f"ë‚ ì§œ í•„í„°ë§ ì™„ë£Œ: {before_filter_count} â†’ {after_filter_count} (target_date: {target_date})")
            
            # ìµœì¢… ë°ì´í„° ê²€ì¦
            if not combined_df.empty:
                time_col = 'time' if 'time' in combined_df.columns else 'datetime'
                if time_col in combined_df.columns:
                    first_time = combined_df[time_col].iloc[0]
                    last_time = combined_df[time_col].iloc[-1]
                    self.logger.info(f"{stock_code} {target_date} ìµœì¢… ë°ì´í„° ë²”ìœ„: {first_time} ~ {last_time}")
                    
                    # 13:30 ì´í›„ ë°ì´í„° ì¡´ì¬ í™•ì¸
                    if time_col == 'time':
                        afternoon_data = combined_df[combined_df[time_col].astype(str).str[:4].astype(int) >= 1330]
                    else:
                        afternoon_data = combined_df[combined_df[time_col].dt.hour * 100 + combined_df[time_col].dt.minute >= 1330]
                    
                    if not afternoon_data.empty:
                        self.logger.info(f"{stock_code} 13:30 ì´í›„ ë°ì´í„°: {len(afternoon_data)}ê±´")
                    else:
                        self.logger.warning(f"{stock_code} 13:30 ì´í›„ ë°ì´í„° ì—†ìŒ!")
            
            self.logger.info(f"{stock_code} {target_date} ì „ì²´ ë¶„ë´‰ ë°ì´í„° ì¡°í•© ì™„ë£Œ: {len(combined_df)}ê±´")
            return combined_df
            
        except Exception as e:
            self.logger.error(f"{stock_code} {target_date} ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def get_timeframe_data(self, stock_code: str, target_date: str, timeframe: str, base_data: pd.DataFrame = None) -> Optional[pd.DataFrame]:
        """
        ì§€ì •ëœ ì‹œê°„í”„ë ˆì„ì˜ ë°ì´í„° ì¡°íšŒ/ë³€í™˜
        
        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            target_date: ë‚ ì§œ
            timeframe: ì‹œê°„í”„ë ˆì„ ("1min", "3min")
            base_data: ê¸°ë³¸ 1ë¶„ë´‰ ë°ì´í„° (ì œê³µë˜ë©´ ì¬ì‚¬ìš©)
            
        Returns:
            pd.DataFrame: ì‹œê°„í”„ë ˆì„ ë°ì´í„°
        """
        try:
            # 1ë¶„ë´‰ ë°ì´í„°ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì¡°íšŒ (base_dataê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
            if base_data is None:
                base_data = asyncio.run(self.get_historical_chart_data(stock_code, target_date))
            
            if base_data is None or base_data.empty:
                self.logger.error(f"âŒ {timeframe} ë³€í™˜ ì‹¤íŒ¨: ê¸°ë³¸ 1ë¶„ë´‰ ë°ì´í„°ê°€ ì—†ìŒ")
                return None
            
            self.logger.error(f"ğŸ” {timeframe} ë³€í™˜ ì…ë ¥ í™•ì¸:")
            self.logger.error(f"   - ì…ë ¥ 1ë¶„ë´‰ ê°œìˆ˜: {len(base_data)}")
            self.logger.error(f"   - ì‹œê°„ ë²”ìœ„: {base_data.iloc[0].get('datetime', base_data.iloc[0].get('time', 'N/A'))} ~ {base_data.iloc[-1].get('datetime', base_data.iloc[-1].get('time', 'N/A'))}")
            
            if timeframe == "1min":
                return base_data
            elif timeframe == "3min":
                # 1ë¶„ë´‰ì„ 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜
                return self._resample_to_3min(base_data)
            elif timeframe == "5min":
                # 1ë¶„ë´‰ì„ 5ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜ (HTSì™€ ë™ì¼í•œ ë°©ì‹)
                self.logger.error(f"   â¡ï¸ 5ë¶„ë´‰ ë³€í™˜ ì‹œì‘...")
                result = self._resample_to_5min(base_data)
                if result is not None:
                    self.logger.error(f"   âœ… 5ë¶„ë´‰ ë³€í™˜ ì™„ë£Œ: {len(result)}ê°œ")
                else:
                    self.logger.error(f"   âŒ 5ë¶„ë´‰ ë³€í™˜ ê²°ê³¼ None")
                return result
            else:
                self.logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„í”„ë ˆì„: {timeframe}")
                return base_data
                
        except Exception as e:
            self.logger.error(f"ì‹œê°„í”„ë ˆì„ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _resample_to_3min(self, data: pd.DataFrame) -> pd.DataFrame:
        """1ë¶„ë´‰ì„ 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜"""
        try:
            if 'datetime' not in data.columns:
                return data
            
            # datetimeì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
            data = data.set_index('datetime')
            
            # 3ë¶„ë´‰ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
            resampled = data.resample('3min').agg({
                'open': 'first',
                'high': 'max', 
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            })
            
            # NaN ì œê±° í›„ ì¸ë±ìŠ¤ ë¦¬ì…‹
            resampled = resampled.dropna().reset_index()
            
            return resampled
            
        except Exception as e:
            self.logger.error(f"3ë¶„ë´‰ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return data
    
    def _resample_to_5min(self, data: pd.DataFrame) -> pd.DataFrame:
        """1ë¶„ë´‰ì„ 5ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜ (ì •í™•í•œ 5ë¶„ ê°„ê²©)"""
        try:
            if data is None or len(data) < 1:
                return data
            
            data = data.copy()
            
            # ì‹œê°„ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            if 'datetime' in data.columns:
                data['datetime'] = pd.to_datetime(data['datetime'])
            elif 'time' in data.columns:
                # time ì»¬ëŸ¼ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
                time_str = data['time'].astype(str).str.zfill(6)  # HHMMSS í˜•ì‹ìœ¼ë¡œ ë§ì¶¤
                data['datetime'] = pd.to_datetime('2024-01-01 ' + 
                                                time_str.str[:2] + ':' + 
                                                time_str.str[2:4] + ':' + 
                                                time_str.str[4:6])
            else:
                self.logger.error("datetime ë˜ëŠ” time ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return data
            
            # ì‹œê°„ìˆœ ì •ë ¬
            data = data.sort_values('datetime').reset_index(drop=True)
            
            self.logger.error(f"ğŸš¨ 5ë¶„ë´‰ ë³€í™˜ ìƒì„¸ ë””ë²„ê¹…:")
            self.logger.error(f"   ğŸ“Š ì…ë ¥ ë°ì´í„°:")
            self.logger.error(f"   - ì´ ë°ì´í„° ê°œìˆ˜: {len(data)}")
            self.logger.error(f"   - ì‹œê°„ ë²”ìœ„: {data['datetime'].iloc[0]} ~ {data['datetime'].iloc[-1]}")
            self.logger.error(f"   - ì „ì²´ ì‹œê°„ span: {(data['datetime'].iloc[-1] - data['datetime'].iloc[0]).total_seconds() / 60:.1f}ë¶„")
            
            # ì „ì²´ ì‹œê°„ ë¶„í¬ í™•ì¸
            time_spread = []
            for i in range(0, len(data), max(1, len(data)//20)):  # 20ê°œ ìƒ˜í”Œ
                dt = data['datetime'].iloc[i]
                time_spread.append(dt.strftime('%H:%M:%S'))
            self.logger.error(f"   - ì‹œê°„ ìƒ˜í”Œ (20ê°œ): {time_spread}")
            
            # ì‹œê°„ ê°„ê²© ë¶„ì„
            if len(data) > 1:
                time_diffs = data['datetime'].diff().dropna()
                unique_intervals = time_diffs.value_counts().head(5)
                self.logger.error(f"   - ì‹œê°„ ê°„ê²© ë¶„í¬: {unique_intervals.to_dict()}")
            
            # 5ë¶„ ê·¸ë£¹í•‘ ì „ ìƒì„¸ ë¶„ì„
            self.logger.error(f"   ğŸ”„ 5ë¶„ ê·¸ë£¹í•‘ ê³¼ì •:")
            data['group_time'] = data['datetime'].dt.floor('5min')  # 5ë¶„ ë‹¨ìœ„ë¡œ ë‚´ë¦¼
            
            unique_groups = data['group_time'].unique()
            sorted_groups = sorted(unique_groups)
            self.logger.error(f"   - ìœ ë‹ˆí¬ 5ë¶„ë´‰ ê·¸ë£¹: {len(unique_groups)}ê°œ")
            self.logger.error(f"   - ì²« 10ê°œ ê·¸ë£¹: {[g.strftime('%H:%M:%S') for g in sorted_groups[:10]]}")
            self.logger.error(f"   - ë§ˆì§€ë§‰ 10ê°œ ê·¸ë£¹: {[g.strftime('%H:%M:%S') for g in sorted_groups[-10:]]}")
            
            # ì´ë¡ ì ìœ¼ë¡œ ìˆì–´ì•¼ í•  5ë¶„ë´‰ë“¤ í™•ì¸
            expected_times = []
            start_time = pd.Timestamp('2024-01-01 08:00:00')
            for i in range(90):  # 08:00 ~ 15:30 = 450ë¶„ Ã· 5ë¶„ = 90ê°œ
                time_str = (start_time + pd.Timedelta(minutes=i*5)).strftime('%H:%M:%S')
                expected_times.append(time_str)
            
            actual_times = [g.strftime('%H:%M:%S') for g in sorted_groups]
            missing_times = set(expected_times) - set(actual_times)
            extra_times = set(actual_times) - set(expected_times)
            
            if missing_times:
                self.logger.error(f"   âŒ ëˆ„ë½ëœ 5ë¶„ë´‰: {sorted(list(missing_times))}")
            if extra_times:
                self.logger.error(f"   â• ì¶”ê°€ëœ 5ë¶„ë´‰: {sorted(list(extra_times))}")
            if len(actual_times) == 77:
                self.logger.error(f"   ğŸ” 77ê°œ vs 78ê°œ ë¬¸ì œ: ì´ë¡ ì  78ê°œ, ì‹¤ì œ {len(actual_times)}ê°œ")
            
            # ê° ê·¸ë£¹ë‹¹ ë°ì´í„° ê°œìˆ˜ í™•ì¸
            group_counts = data['group_time'].value_counts().sort_index()
            self.logger.error(f"   - ê° 5ë¶„ë´‰ ê·¸ë£¹ë‹¹ 1ë¶„ë´‰ ê°œìˆ˜:")
            for i, (group_time, count) in enumerate(group_counts.head(10).items()):
                self.logger.error(f"     {group_time.strftime('%H:%M:%S')}: {count}ê°œ 1ë¶„ë´‰")
            
            if len(group_counts) != len(unique_groups):
                self.logger.error(f"   âš ï¸ ê·¸ë£¹ ê°œìˆ˜ ë¶ˆì¼ì¹˜: unique={len(unique_groups)}, counts={len(group_counts)}")
            
            # ê·¸ë£¹ë³„ë¡œ OHLCV ê³„ì‚°
            grouped = data.groupby('group_time').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min', 
                'close': 'last',
                'volume': 'sum'
            }).reset_index()
            
            # datetimeê³¼ time ì»¬ëŸ¼ ì¶”ê°€
            grouped['datetime'] = grouped['group_time']
            grouped['time'] = grouped['datetime'].dt.strftime('%H%M%S')
            grouped = grouped.drop('group_time', axis=1)
            
            self.logger.error(f"ğŸ¯ 5ë¶„ë´‰ ë³€í™˜ ìµœì¢… ê²°ê³¼:")
            self.logger.error(f"   - ì…ë ¥ 1ë¶„ë´‰: {len(data)}ê°œ")
            self.logger.error(f"   - ì¶œë ¥ 5ë¶„ë´‰: {len(grouped)}ê°œ")
            self.logger.error(f"   - ì´ë¡ ì  5ë¶„ë´‰ ê°œìˆ˜: {(data['datetime'].iloc[-1] - data['datetime'].iloc[0]).total_seconds() / 60 / 5:.1f}ê°œ")
            
            if not grouped.empty:
                self.logger.error(f"   - 5ë¶„ë´‰ ì‹œê°„ ë²”ìœ„: {grouped['datetime'].iloc[0]} ~ {grouped['datetime'].iloc[-1]}")
                self.logger.error(f"   - ì „ì²´ 5ë¶„ë´‰ ì‹œê°„ë“¤: {grouped['time'].tolist()}")
                
                # ì—°ì†ì„± í™•ì¸
                if len(grouped) > 1:
                    time_diffs = grouped['datetime'].diff().dropna()
                    intervals = [f'{td.total_seconds()/60:.0f}ë¶„' for td in time_diffs]
                    self.logger.error(f"   - 5ë¶„ë´‰ ê°„ê²©ë“¤: {intervals}")
                    
                    # 5ë¶„ ê°„ê²©ì´ ì•„ë‹Œ ê²ƒë“¤ ì°¾ê¸°
                    non_5min_gaps = time_diffs[time_diffs != pd.Timedelta(minutes=5)]
                    if not non_5min_gaps.empty:
                        self.logger.error(f"   âš ï¸ ë¹„ì •ìƒ ê°„ê²© ë°œê²¬:")
                        for i, gap in enumerate(non_5min_gaps):
                            gap_minutes = gap.total_seconds() / 60
                            self.logger.error(f"     {i+1}: {gap_minutes:.0f}ë¶„ ê°„ê²©")
                else:
                    self.logger.error("   âš ï¸ 5ë¶„ë´‰ì´ 1ê°œë§Œ ìƒì„±ë¨ - ì´ê²ƒì´ ë¬¸ì œ!")
                    
                # ë§ˆì§€ë§‰ìœ¼ë¡œ ê° 5ë¶„ë´‰ì˜ OHLCV ê°’ í™•ì¸ (ì²˜ìŒ 5ê°œ)
                self.logger.error(f"   - ì²˜ìŒ 5ê°œ 5ë¶„ë´‰ OHLCV:")
                for i in range(min(5, len(grouped))):
                    row = grouped.iloc[i]
                    self.logger.error(f"     {row['time']}: O={row['open']:.0f}, H={row['high']:.0f}, L={row['low']:.0f}, C={row['close']:.0f}, V={row['volume']}")
            else:
                self.logger.error("   âŒ 5ë¶„ë´‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ!")
            
            return grouped
            
        except Exception as e:
            self.logger.error(f"âŒ 5ë¶„ë´‰ ë³€í™˜ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return data
    
    def calculate_indicators_with_daily_data(self, data: pd.DataFrame, strategy, 
                                            daily_data: Optional[pd.DataFrame] = None,
                                            current_price: Optional[float] = None) -> Dict[str, Any]:
        """
        ì¼ë´‰ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì§€í‘œ ê³„ì‚° (ê°€ê²©ë°•ìŠ¤ìš©)
        
        Args:
            data: ë¶„ë´‰ ê°€ê²© ë°ì´í„°
            strategy: ê±°ë˜ ì „ëµ
            daily_data: ê³¼ê±° 29ì¼ ì¼ë´‰ ë°ì´í„°
            current_price: í˜„ì¬ ê°€ê²©
            
        Returns:
            Dict: ê³„ì‚°ëœ ì§€í‘œ ë°ì´í„°
        """
        try:
            indicators_data = {}
            
            if 'close' not in data.columns:
                self.logger.warning("ê°€ê²© ë°ì´í„°ì— 'close' ì»¬ëŸ¼ì´ ì—†ìŒ")
                return {}
            
            for indicator_name in strategy.indicators:
                if indicator_name == "price_box":
                    # ê°€ê²©ë°•ìŠ¤ëŠ” 1ë¶„ë´‰ ê¸°ì¤€: ê· ì¼ 1ë¶„ ê·¸ë¦¬ë“œë¡œ ë³´ì • í›„ period=30 ì ìš©, ê·¸ë¦¬ê³  ì‹¤ì œ ë°ì´í„° íƒ€ì„ìŠ¤íƒ¬í”„ì— ì¬ìƒ‰ì¸
                    try:
                        uniform_close = self._get_uniform_1min_close(data)
                        series_to_use = uniform_close if uniform_close is not None else pd.to_numeric(data['close'], errors='coerce')
                        box = PriceBox.calculate_price_box(series_to_use, period=30)
                        if box and 'center_line' in box:
                            box_aligned = self._reindex_price_box_to_data(box, data)
                            indicators_data["price_box"] = {
                                'center': box_aligned['center_line'],
                                'resistance': box_aligned['upper_band'],
                                'support': box_aligned['lower_band']
                            }
                    except Exception as e:
                        self.logger.error(f"ê°€ê²©ë°•ìŠ¤ ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "bisector_line":
                    # ì´ë“±ë¶„ì„  ê³„ì‚°
                    try:
                        if 'high' in data.columns and 'low' in data.columns:
                            bisector_values = BisectorLine.calculate_bisector_line(data['high'], data['low'])
                            if bisector_values is not None:
                                indicators_data["bisector_line"] = {
                                    'line_values': bisector_values
                                }
                    except Exception as e:
                        self.logger.error(f"ì´ë“±ë¶„ì„  ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "bollinger_bands":
                    # ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°
                    try:
                        bb_result = BollingerBands.calculate_bollinger_bands(data['close'])
                        if bb_result and 'center_line' in bb_result:
                            indicators_data["bollinger_bands"] = bb_result
                    except Exception as e:
                        self.logger.error(f"ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "multi_bollinger_bands":
                    # ë‹¤ì¤‘ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°
                    try:
                        from core.indicators.multi_bollinger_bands import MultiBollingerBands
                        multi_bb = MultiBollingerBands.calculate_multi_bollinger_bands(data['close'])
                        if multi_bb:
                            indicators_data["multi_bollinger_bands"] = multi_bb
                    except Exception as e:
                        self.logger.error(f"ë‹¤ì¤‘ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "pullback_candle_pattern":
                    # ëˆŒë¦¼ëª© ìº”ë“¤íŒ¨í„´ì€ ê°œë³„ ì„  ì—†ì´ ì‹ í˜¸ ê¸°ë°˜ í‘œì‹œ(ì°¨íŠ¸ ë Œë”ëŸ¬ì—ì„œ ì²˜ë¦¬)
                    try:
                        pass
                    except Exception as e:
                        self.logger.error(f"ëˆŒë¦¼ëª© ìº”ë“¤íŒ¨í„´ ê³„ì‚° ì˜¤ë¥˜: {e}")
            
            return indicators_data
            
        except Exception as e:
            self.logger.error(f"ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def _combine_daily_and_intraday_data(self, daily_data: pd.DataFrame, intraday_data: pd.DataFrame, 
                                       current_price: Optional[float] = None) -> Optional[pd.Series]:
        """
        ì¼ë´‰ ë°ì´í„°ì™€ ë¶„ë´‰ ë°ì´í„°ë¥¼ ì¡°í•©í•˜ì—¬ 30ì¼ ê°€ê²© ì‹œë¦¬ì¦ˆ ìƒì„±
        
        Args:
            daily_data: ê³¼ê±° ì¼ë´‰ ë°ì´í„° (29ì¼)
            intraday_data: ë‹¹ì¼ ë¶„ë´‰ ë°ì´í„° 
            current_price: í˜„ì¬ ê°€ê²© (ì„ íƒì‚¬í•­)
            
        Returns:
            pd.Series: ì¡°í•©ëœ 30ì¼ ê°€ê²© ì‹œë¦¬ì¦ˆ (29ì¼ ì¼ë´‰ ì¢…ê°€ + ë‹¹ì¼ ë¶„ë´‰ ì¢…ê°€ë“¤)
        """
        try:
            # 1. ì¼ë´‰ ì¢…ê°€ ì¶”ì¶œ (29ì¼)
            close_col = None
            for col in ['stck_clpr', 'close', 'Close', 'CLOSE', 'clpr']:
                if col in daily_data.columns:
                    close_col = col
                    break
            
            if close_col is None:
                self.logger.warning("ì¼ë´‰ ë°ì´í„°ì—ì„œ ì¢…ê°€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
            
            daily_closes = pd.to_numeric(daily_data[close_col], errors='coerce').dropna()
            
            if len(daily_closes) < 88:
                self.logger.warning(f"ì¼ë´‰ ë°ì´í„° ë¶€ì¡±: {len(daily_closes)}ì¼ (9ì‹œë¶€í„° TMA30 ê³„ì‚°ì„ ìœ„í•´ ìµœì†Œ 88ì¼ í•„ìš”)")
                return None
            
            # ìµœê·¼ 88ì¼ ì„ íƒ (ë‹¹ì¼ 9ì‹œ ì²« ë¶„ë´‰ë¶€í„° TMA30 ê³„ì‚° ê°€ëŠ¥í•˜ë„ë¡)
            daily_closes = daily_closes.tail(88)
            
            # 2. ë¶„ë´‰ ì¢…ê°€ ì¶”ì¶œ (ë‹¹ì¼)
            if 'close' not in intraday_data.columns:
                self.logger.warning("ë¶„ë´‰ ë°ì´í„°ì— 'close' ì»¬ëŸ¼ì´ ì—†ìŒ")
                return None
            
            intraday_closes = pd.to_numeric(intraday_data['close'], errors='coerce').dropna()
            
            if len(intraday_closes) == 0:
                self.logger.warning("ìœ íš¨í•œ ë¶„ë´‰ ì¢…ê°€ ë°ì´í„°ê°€ ì—†ìŒ")
                return None
            
            # 3. ë°ì´í„° ì¡°í•©: [29ì¼ ì¼ë´‰ ì¢…ê°€] + [ë‹¹ì¼ ë¶„ë´‰ ì¢…ê°€ë“¤]
            # 29ì¼ ì¼ë´‰ ì¢…ê°€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            daily_list = daily_closes.tolist()
            
            # ë‹¹ì¼ ë¶„ë´‰ ì¢…ê°€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            intraday_list = intraday_closes.tolist()
            
            # ì¡°í•©
            combined_list = daily_list + intraday_list
            
            # pandas Seriesë¡œ ë³€í™˜ (ì¸ë±ìŠ¤ëŠ” ë¶„ë´‰ ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤)
            # ë§ˆì§€ë§‰ ë¶„ë´‰ ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ ì‚¬ìš©
            if len(intraday_list) > 0:
                # ë¶„ë´‰ ë°ì´í„° ê¸¸ì´ì— ë§ì¶° ì „ì²´ ì¡°í•© ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ì‹±
                combined_series = pd.Series(combined_list, index=range(len(combined_list)))
                
                # ë¶„ë´‰ ì¸ë±ìŠ¤ì— ë§ê²Œ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
                intraday_length = len(intraday_data)
                if len(combined_series) >= intraday_length:
                    result_series = pd.Series(combined_list[-intraday_length:], index=intraday_data.index)
                else:
                    # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë°ì´í„° ì‚¬ìš©
                    result_series = pd.Series(combined_list, index=intraday_data.index[:len(combined_list)])
                
                self.logger.info(f"âœ… ì¼ë´‰+ë¶„ë´‰ ë°ì´í„° ì¡°í•© ì„±ê³µ: ì¼ë´‰ {len(daily_list)}ì¼ (ê³¼ê±° 88ì¼) + ë¶„ë´‰ {len(intraday_list)}ê°œ = ì´ {len(combined_list)}ê°œ")
                return result_series
            else:
                return None
            
        except Exception as e:
            self.logger.error(f"ì¼ë´‰+ë¶„ë´‰ ë°ì´í„° ì¡°í•© ì˜¤ë¥˜: {e}")
            return None
    
    def calculate_indicators(self, data: pd.DataFrame, strategy) -> Dict[str, Any]:
        """
        ì „ëµì— ë”°ë¥¸ ì§€í‘œ ê³„ì‚°
        
        Args:
            data: ê°€ê²© ë°ì´í„°
            strategy: ê±°ë˜ ì „ëµ
            
        Returns:
            Dict: ê³„ì‚°ëœ ì§€í‘œ ë°ì´í„°
        """
        try:
            indicators_data = {}
            
            if 'close' not in data.columns:
                self.logger.warning("ê°€ê²© ë°ì´í„°ì— 'close' ì»¬ëŸ¼ì´ ì—†ìŒ")
                return {}
            
            for indicator_name in strategy.indicators:
                if indicator_name == "price_box":
                    # ê°€ê²©ë°•ìŠ¤ ê³„ì‚°
                    try:
                        price_box_result = PriceBox.calculate_price_box(data['close'])
                        if price_box_result and 'center_line' in price_box_result:
                            indicators_data["price_box"] = {
                                'center': price_box_result['center_line'],
                                'resistance': price_box_result['upper_band'],
                                'support': price_box_result['lower_band']
                            }
                    except Exception as e:
                        self.logger.error(f"ê°€ê²©ë°•ìŠ¤ ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "bisector_line":
                    # ì´ë“±ë¶„ì„  ê³„ì‚°
                    try:
                        if 'high' in data.columns and 'low' in data.columns:
                            bisector_values = BisectorLine.calculate_bisector_line(data['high'], data['low'])
                            if bisector_values is not None:
                                indicators_data["bisector_line"] = {
                                    'line_values': bisector_values
                                }
                    except Exception as e:
                        self.logger.error(f"ì´ë“±ë¶„ì„  ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "bollinger_bands":
                    # ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°
                    try:
                        bb_result = BollingerBands.calculate_bollinger_bands(data['close'])
                        if bb_result and 'upper_band' in bb_result:
                            indicators_data["bollinger_bands"] = {
                                'upper': bb_result['upper_band'],
                                'middle': bb_result['sma'],
                                'lower': bb_result['lower_band']
                            }
                    except Exception as e:
                        self.logger.error(f"ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì˜¤ë¥˜: {e}")
                
                elif indicator_name == "multi_bollinger_bands":
                    # ë‹¤ì¤‘ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°
                    try:
                        # MultiBollingerBands.generate_trading_signals ì‚¬ìš©
                        signals_df = MultiBollingerBands.generate_trading_signals(data['close'])
                        
                        if not signals_df.empty:
                            # ê° ê¸°ê°„ë³„ ë°ì´í„° ì¶”ì¶œ
                            multi_bb_data = {}
                            for period in [50, 40, 30, 20]:
                                sma_key = f'sma_{period}'
                                upper_key = f'upper_{period}'
                                lower_key = f'lower_{period}'
                                
                                if all(key in signals_df.columns for key in [sma_key, upper_key, lower_key]):
                                    multi_bb_data[sma_key] = signals_df[sma_key]
                                    multi_bb_data[upper_key] = signals_df[upper_key]
                                    multi_bb_data[lower_key] = signals_df[lower_key]
                            
                            # ìƒí•œì„  ë°€ì§‘ë„ì™€ ì´ë“±ë¶„ì„  ì¶”ê°€
                            if 'upper_convergence' in signals_df.columns:
                                multi_bb_data['upper_convergence'] = signals_df['upper_convergence']
                            
                            if 'bisector_line' in signals_df.columns:
                                multi_bb_data['bisector_line'] = signals_df['bisector_line']
                            
                            indicators_data["multi_bollinger_bands"] = multi_bb_data
                            
                    except Exception as e:
                        self.logger.error(f"ë‹¤ì¤‘ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì˜¤ë¥˜: {e}")
            
            return indicators_data
            
        except Exception as e:
            self.logger.error(f"ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def validate_and_clean_data(self, data: pd.DataFrame, target_date: str = None) -> pd.DataFrame:
        """ë°ì´í„° ê²€ì¦ ë° ì¤‘ë³µ ì œê±°"""
        try:
            if data.empty:
                return data
                
            # ë‚ ì§œ í•„í„°ë§ (target_dateê°€ ì œê³µëœ ê²½ìš°)
            if target_date:
                original_count = len(data)
                if 'datetime' in data.columns:
                    # datetime ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                    data['date_str'] = pd.to_datetime(data['datetime']).dt.strftime('%Y%m%d')
                    data = data[data['date_str'] == target_date].drop('date_str', axis=1)
                elif 'time' in data.columns:
                    # time ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° (YYYYMMDDHHMM í˜•ì‹)
                    data['date_str'] = data['time'].astype(str).str[:8]
                    data = data[data['date_str'] == target_date].drop('date_str', axis=1)
                
                if len(data) != original_count:
                    self.logger.info(f"ë‚ ì§œ í•„í„°ë§ ì™„ë£Œ: {original_count} â†’ {len(data)} (target_date: {target_date})")
            
            if 'time' not in data.columns:
                return data
            
            # ì‹œê°„ ì¤‘ë³µ ì œê±°
            original_count = len(data)
            cleaned_data = data.drop_duplicates(subset=['time'], keep='first')
            
            if len(cleaned_data) != original_count:
                self.logger.warning(f"ì¤‘ë³µ ì‹œê°„ ë°ì´í„° ì œê±°: {original_count} â†’ {len(cleaned_data)}")
            
            # ì‹œê°„ ìˆœ ì •ë ¬
            cleaned_data = cleaned_data.sort_values('time')
            
            # ì¸ë±ìŠ¤ ì¬ì„¤ì •
            cleaned_data = cleaned_data.reset_index(drop=True)
            
            return cleaned_data
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜: {e}")
            return data
#!/usr/bin/env python3
"""
ML ëª¨ë¸ í•™ìŠµ (Stratified ë¶„í•  ë°©ì‹)

ê°œì„  ì‚¬í•­:
- Stratified K-Foldë¡œ ë°ì´í„° ë¶„í•  (ì‹œê°„ ê¸°ë°˜ â†’ ë¼ë²¨ ê¸°ë°˜)
- ê³¼ì í•© ë°©ì§€ ê°•í™” (ì •ê·œí™”, ë“œë¡­ì•„ì›ƒ)
- íŠ¹ì„± ì„ íƒ (ì¤‘ìš”ë„ ë‚®ì€ íŠ¹ì„± ì œê±°)
"""

import pandas as pd
import numpy as np
import sys
from pathlib import Path
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve
)
import lightgbm as lgb
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pickle

sys.stdout.reconfigure(encoding='utf-8')


def load_and_prepare_data(csv_file: str = 'ml_dataset.csv'):
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("=" * 70)
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘... (Stratified ë°©ì‹)")
    print("=" * 70)

    df = pd.read_csv(csv_file, encoding='utf-8-sig')
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")

    # ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼ ì œê±°
    meta_cols = ['stock_code', 'pattern_id', 'timestamp', 'sell_reason', 'profit_rate']
    feature_cols = [col for col in df.columns if col not in meta_cols + ['label']]

    X = df[feature_cols].copy()
    y = df['label'].copy()

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    le = LabelEncoder()
    if 'signal_type' in X.columns:
        X['signal_type'] = le.fit_transform(X['signal_type'])

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    X = X.fillna(0)

    print(f"\níŠ¹ì§•(feature) ìˆ˜: {len(feature_cols)}")
    print(f"ë¼ë²¨ ë¶„í¬: ìŠ¹ë¦¬={y.sum()} ({y.mean()*100:.1f}%), íŒ¨ë°°={len(y)-y.sum()} ({(1-y.mean())*100:.1f}%)")

    return X, y, feature_cols, le


def train_with_stratified_kfold(X, y, feature_names, n_splits=5):
    """Stratified K-Fold êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ"""
    print("\n" + "=" * 70)
    print(f"ğŸ”„ Stratified {n_splits}-Fold êµì°¨ ê²€ì¦")
    print("=" * 70)

    # ê³¼ì í•© ë°©ì§€ ê°•í™” íŒŒë¼ë¯¸í„°
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 15,           # 31 â†’ 15 (ë³µì¡ë„ ê°ì†Œ)
        'learning_rate': 0.01,      # 0.05 â†’ 0.01 (ë” ëŠë¦¬ê²Œ í•™ìŠµ)
        'feature_fraction': 0.6,    # 0.8 â†’ 0.6 (ë” ë§ì€ ë“œë¡­ì•„ì›ƒ)
        'bagging_fraction': 0.6,    # 0.8 â†’ 0.6
        'bagging_freq': 5,
        'min_data_in_leaf': 50,     # 20 â†’ 50 (ë” ë³´ìˆ˜ì )
        'max_depth': 4,             # 6 â†’ 4 (ë” ì–•ì€ íŠ¸ë¦¬)
        'lambda_l1': 1.0,           # L1 ì •ê·œí™” ê°•í™”
        'lambda_l2': 1.0,           # L2 ì •ê·œí™” ê°•í™”
        'verbose': -1,
        'seed': 42
    }

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    cv_scores = []
    models = []
    fold_results = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
        print(f"\nğŸ“Š Fold {fold}/{n_splits}")
        print("-" * 70)

        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]

        print(f"  í•™ìŠµ: {len(X_train_fold)}ê°œ (ìŠ¹ë¥  {y_train_fold.mean()*100:.1f}%)")
        print(f"  ê²€ì¦: {len(X_val_fold)}ê°œ (ìŠ¹ë¥  {y_val_fold.mean()*100:.1f}%)")

        # ë°ì´í„°ì…‹ ìƒì„±
        lgb_train = lgb.Dataset(X_train_fold, y_train_fold, feature_name=feature_names)
        lgb_val = lgb.Dataset(X_val_fold, y_val_fold, reference=lgb_train, feature_name=feature_names)

        # í•™ìŠµ
        model = lgb.train(
            params,
            lgb_train,
            num_boost_round=1000,
            valid_sets=[lgb_train, lgb_val],
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=100),
                lgb.log_evaluation(period=0)  # ì¶œë ¥ ì–µì œ
            ]
        )

        # í‰ê°€
        y_pred_proba = model.predict(X_val_fold, num_iteration=model.best_iteration)
        auc = roc_auc_score(y_val_fold, y_pred_proba)
        cv_scores.append(auc)
        models.append(model)

        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        y_pred = (y_pred_proba > 0.5).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_val_fold, y_pred).ravel()

        fold_results.append({
            'fold': fold,
            'auc': auc,
            'accuracy': (tp + tn) / (tp + tn + fp + fn),
            'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,
            'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,
            'best_iteration': model.best_iteration
        })

        print(f"  âœ… Fold {fold} AUC: {auc:.4f} (ë°˜ë³µ: {model.best_iteration})")

    # í‰ê·  ì„±ëŠ¥
    print("\n" + "=" * 70)
    print("ğŸ“ˆ êµì°¨ ê²€ì¦ ê²°ê³¼")
    print("=" * 70)
    print(f"í‰ê·  AUC: {np.mean(cv_scores):.4f} (Â± {np.std(cv_scores):.4f})")
    print(f"ìµœì†Œ AUC: {np.min(cv_scores):.4f}")
    print(f"ìµœëŒ€ AUC: {np.max(cv_scores):.4f}")

    print("\nFoldë³„ ìƒì„¸ ê²°ê³¼:")
    print("-" * 70)
    for result in fold_results:
        print(f"Fold {result['fold']}: AUC={result['auc']:.4f}, "
              f"ì •í™•ë„={result['accuracy']:.4f}, "
              f"ì •ë°€ë„={result['precision']:.4f}, "
              f"ì¬í˜„ìœ¨={result['recall']:.4f}")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
    best_fold_idx = np.argmax(cv_scores)
    best_model = models[best_fold_idx]

    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: Fold {best_fold_idx + 1} (AUC: {cv_scores[best_fold_idx]:.4f})")

    return best_model, cv_scores, fold_results


def final_evaluation(model, X, y, feature_names, output_dir='ml_results_stratified'):
    """ìµœì¢… í‰ê°€ (ì „ì²´ ë°ì´í„°ì˜ 20%ë¥¼ í™€ë“œì•„ì›ƒ)"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ìµœì¢… í™€ë“œì•„ì›ƒ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    Path(output_dir).mkdir(exist_ok=True)

    # ì „ì²´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ 20%ë¥¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©
    test_size = int(len(X) * 0.2)

    X_test = X.iloc[-test_size:]
    y_test = y.iloc[-test_size:]

    print(f"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(X_test)}ê°œ (ìŠ¹ë¥  {y_test.mean()*100:.1f}%)")

    # ì˜ˆì¸¡
    y_pred_proba = model.predict(X_test, num_iteration=model.best_iteration)
    y_pred = (y_pred_proba > 0.5).astype(int)

    # ì„±ëŠ¥ ì§€í‘œ
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(classification_report(y_test, y_pred, target_names=['íŒ¨ë°°', 'ìŠ¹ë¦¬']))

    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_test, y_pred)
    print("\ní˜¼ë™ í–‰ë ¬:")
    print(f"             ì˜ˆì¸¡: íŒ¨ë°°  ì˜ˆì¸¡: ìŠ¹ë¦¬")
    print(f"ì‹¤ì œ íŒ¨ë°°:   {cm[0][0]:>6}    {cm[0][1]:>6}")
    print(f"ì‹¤ì œ ìŠ¹ë¦¬:   {cm[1][0]:>6}    {cm[1][1]:>6}")

    # AUC
    auc_score = roc_auc_score(y_test, y_pred_proba)
    print(f"\nğŸ¯ í™€ë“œì•„ì›ƒ í…ŒìŠ¤íŠ¸ AUC: {auc_score:.4f}")

    # ROC Curve ì €ì¥
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    plt.figure(figsize=(10, 6))
    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - Stratified Model')
    plt.legend()
    plt.grid(True)
    plt.savefig(f'{output_dir}/roc_curve_stratified.png', dpi=150)
    print(f"âœ… ROC Curve ì €ì¥: {output_dir}/roc_curve_stratified.png")

    # Feature Importance
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importance(importance_type='gain')
    }).sort_values('importance', ascending=False)

    print("\nğŸ” Top 20 ì¤‘ìš” íŠ¹ì„±:")
    for i, row in importance_df.head(20).iterrows():
        print(f"  {row['feature']:30s}: {row['importance']:>10.0f}")

    # Feature Importance ê·¸ë˜í”„
    plt.figure(figsize=(12, 10))
    top_features = importance_df.head(30)
    plt.barh(range(len(top_features)), top_features['importance'])
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Importance (Gain)')
    plt.title('Top 30 Feature Importance - Stratified Model')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig(f'{output_dir}/feature_importance_stratified.png', dpi=150)
    print(f"âœ… Feature Importance ì €ì¥: {output_dir}/feature_importance_stratified.png")

    # CSV ì €ì¥
    importance_df.to_csv(f'{output_dir}/feature_importance_stratified.csv', index=False, encoding='utf-8-sig')

    return auc_score, importance_df


def save_model(model, label_encoder, feature_names, cv_scores, output_file='ml_model_stratified.pkl'):
    """ëª¨ë¸ ì €ì¥"""
    model_data = {
        'model': model,
        'label_encoder': label_encoder,
        'feature_names': feature_names,
        'cv_scores': cv_scores,
        'version': 'stratified',
        'description': 'LightGBM with Stratified K-Fold and overfitting prevention'
    }

    with open(output_file, 'wb') as f:
        pickle.dump(model_data, f)

    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_file}")
    print(f"   ëª¨ë¸ í¬ê¸°: {Path(output_file).stat().st_size / 1024:.1f} KB")


def main():
    print("=" * 70)
    print("ğŸ¤– ML ëª¨ë¸ í•™ìŠµ ì‹œìŠ¤í…œ (Stratified ë°©ì‹)")
    print("=" * 70)

    # 1. ë°ì´í„° ë¡œë“œ
    X, y, feature_names, label_encoder = load_and_prepare_data('ml_dataset.csv')

    # 2. Stratified K-Fold êµì°¨ ê²€ì¦
    best_model, cv_scores, fold_results = train_with_stratified_kfold(X, y, feature_names, n_splits=5)

    # 3. ìµœì¢… í‰ê°€ (í™€ë“œì•„ì›ƒ í…ŒìŠ¤íŠ¸)
    test_auc, importance_df = final_evaluation(best_model, X, y, feature_names)

    # 4. ëª¨ë¸ ì €ì¥
    save_model(best_model, label_encoder, feature_names, cv_scores, 'ml_model_stratified.pkl')

    # 5. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“ˆ ìµœì¢… ì„±ê³¼ ìš”ì•½")
    print("=" * 70)
    print(f"êµì°¨ ê²€ì¦ í‰ê·  AUC: {np.mean(cv_scores):.4f} (Â± {np.std(cv_scores):.4f})")
    print(f"í™€ë“œì•„ì›ƒ í…ŒìŠ¤íŠ¸ AUC: {test_auc:.4f}")
    print(f"\níŠ¹ì„± ìˆ˜: {len(feature_names)}ê°œ")
    print(f"ìƒ˜í”Œ ìˆ˜: {len(X)}ê°œ")

    # ê³¼ì í•© ì²´í¬
    cv_mean = np.mean(cv_scores)
    overfit_gap = cv_mean - test_auc
    print(f"\nê³¼ì í•© ì²´í¬:")
    print(f"  êµì°¨ê²€ì¦-í…ŒìŠ¤íŠ¸ ì°¨ì´: {overfit_gap:.4f} ({overfit_gap*100:.1f}%p)")

    if overfit_gap < 0.05:
        print("  âœ… ê³¼ì í•© ì—†ìŒ (ì°¨ì´ < 5%p)")
    elif overfit_gap < 0.10:
        print("  âš ï¸ ê²½ë¯¸í•œ ê³¼ì í•© (ì°¨ì´ 5-10%p)")
    else:
        print("  ğŸš¨ ê³¼ì í•© ë°œìƒ (ì°¨ì´ > 10%p)")

    print("\n" + "=" * 70)
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„")
    print("=" * 70)
    print("1. ë°±í…ŒìŠ¤íŠ¸ ìˆ˜í–‰:")
    print("   python batch_signal_replay_ml.py --start 20250901 --end 20251118")
    print("\n2. apply_ml_filter.pyì—ì„œ ëª¨ë¸ íŒŒì¼ëª… ë³€ê²½:")
    print("   ml_model.pkl â†’ ml_model_stratified.pkl")


if __name__ == '__main__':
    main()

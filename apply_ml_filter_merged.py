#!/usr/bin/env python3
"""
ë³‘í•© ML ëª¨ë¸ (ml_model_merged.pkl)ë¡œ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•„í„°ë§

ê¸°ì¡´ apply_ml_filter.pyì™€ ë™ì¼í•˜ì§€ë§Œ ml_model_merged.pkl ì‚¬ìš©
- AUC 0.7508
- ìµœì  threshold 0.6 (77.4% ìŠ¹ë¥ )
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

import pickle
import re
import json
import sqlite3
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import pandas as pd


def load_stock_names() -> Dict[str, str]:
    """DBì—ì„œ ì¢…ëª© ì½”ë“œ-ì¢…ëª©ëª… ë§¤í•‘ ë¡œë“œ"""
    try:
        conn = sqlite3.connect('data/robotrader.db')
        cursor = conn.cursor()

        cursor.execute("SELECT DISTINCT stock_code, stock_name FROM candidate_stocks WHERE stock_name IS NOT NULL")
        stock_map = {code: name for code, name in cursor.fetchall()}

        conn.close()
        print(f"âœ… ì¢…ëª©ëª… ë¡œë“œ ì™„ë£Œ: {len(stock_map)}ê°œ")
        return stock_map
    except Exception as e:
        print(f"âš ï¸  ì¢…ëª©ëª… ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def load_ml_model(model_path: str = "ml_model_merged.pkl"):
    """ë³‘í•© ML ëª¨ë¸ ë¡œë“œ"""
    try:
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)

        model = model_data['model']
        feature_names = model_data['feature_names']

        print(f"âœ… ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path} ({len(feature_names)}ê°œ íŠ¹ì„±)")
        return model, feature_names

    except Exception as e:
        print(f"âŒ ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def parse_signal_from_log_line(line: str) -> Dict:
    """
    ë¡œê·¸ ë¼ì¸ì—ì„œ ì‹ í˜¸ ì •ë³´ íŒŒì‹±

    ì˜ˆì‹œ ë¼ì¸:
    "   ğŸŸ¢ 174900 09:21 ë§¤ìˆ˜ â†’ +3.50%"
    "   ğŸŸ¢ 174900(ì¢…ëª©ëª…) 09:21 ë§¤ìˆ˜ â†’ +3.50%"
    """
    # ì‹ í˜¸ íŒ¨í„´ ë§¤ì¹­ (ì¢…ëª©ëª… ìˆì„ ìˆ˜ë„, ì—†ì„ ìˆ˜ë„)
    pattern = r'[ğŸ”´ğŸŸ¢]\s+(\d{6})(?:\([^)]+\))?\s+(\d{2}):(\d{2})\s+ë§¤ìˆ˜\s+â†’\s+([-+]\d+\.\d+)%'
    match = re.search(pattern, line)

    if not match:
        return None

    stock_code = match.group(1)
    hour = int(match.group(2))
    minute = int(match.group(3))
    profit_rate = float(match.group(4))

    return {
        'stock_code': stock_code,
        'hour': hour,
        'minute': minute,
        'time': f"{hour:02d}:{minute:02d}",
        'profit_rate': profit_rate,
        'is_win': profit_rate > 0
    }


def load_pattern_data_for_date(date_str: str) -> Dict[str, Dict]:
    """
    íŠ¹ì • ë‚ ì§œì˜ íŒ¨í„´ ë°ì´í„° ë¡œë“œ

    Returns:
        Dict[pattern_id, pattern_data]
    """
    pattern_log_file = Path('pattern_data_log') / f'pattern_data_{date_str}.jsonl'

    if not pattern_log_file.exists():
        print(f"   âš ï¸  íŒ¨í„´ ë¡œê·¸ ì—†ìŒ: {pattern_log_file}")
        return {}

    patterns = {}
    try:
        with open(pattern_log_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    try:
                        record = json.loads(line)
                        pattern_id = record.get('pattern_id', '')
                        if pattern_id:
                            patterns[pattern_id] = record
                    except:
                        pass

        print(f"   ğŸ“Š íŒ¨í„´ ë°ì´í„° ë¡œë“œ: {len(patterns)}ê°œ")
        return patterns

    except Exception as e:
        print(f"   âš ï¸  íŒ¨í„´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def find_matching_pattern(patterns: Dict[str, Dict], signal: Dict) -> Optional[Dict]:
    """
    ì‹ í˜¸ì™€ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì°¾ê¸° (Â±5ë¶„ ë²”ìœ„ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ ì„ íƒ)

    ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸ì˜ ë§¤ìˆ˜ ì‹œê°„ Â±5ë¶„ ë²”ìœ„ ë‚´ì—ì„œ íŒ¨í„´ì„ ì°¾ê³ ,
    ê·¸ ì¤‘ ì‹œê°„ ì°¨ì´ê°€ ê°€ì¥ ì‘ì€ íŒ¨í„´ì„ ì„ íƒí•©ë‹ˆë‹¤.
    """
    stock_code = signal['stock_code']
    hour = signal['hour']
    minute = signal['minute']

    # ëŒ€ìƒ ì‹œê°„ (ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜)
    target_minutes = hour * 60 + minute

    matched_patterns = []

    for pattern_id, pattern_data in patterns.items():
        parts = pattern_id.split('_')
        if len(parts) >= 3:
            p_code = parts[0]

            if p_code == stock_code:
                # signal_timeìœ¼ë¡œ ë§¤ì¹­
                signal_time_str = pattern_data.get('signal_time', '')
                if signal_time_str:
                    try:
                        # "2025-12-08 10:12:00" -> datetime
                        st = datetime.strptime(signal_time_str, '%Y-%m-%d %H:%M:%S')
                        pattern_minutes = st.hour * 60 + st.minute

                        # ì‹œê°„ ì°¨ì´ ê³„ì‚° (ì ˆëŒ€ê°’)
                        time_diff = abs(pattern_minutes - target_minutes)

                        # Â±5ë¶„ ë²”ìœ„ ë‚´ì— ìˆìœ¼ë©´ í›„ë³´ì— ì¶”ê°€
                        if time_diff <= 5:
                            log_timestamp = pattern_data.get('log_timestamp', signal_time_str)
                            matched_patterns.append({
                                'pattern_data': pattern_data,
                                'log_timestamp': log_timestamp,
                                'pattern_id': pattern_id,
                                'time_diff': time_diff
                            })
                    except:
                        pass

    if not matched_patterns:
        return None

    # 1ìˆœìœ„: ì‹œê°„ ì°¨ì´ê°€ ê°€ì¥ ì‘ì€ ê²ƒ (ì˜¤ë¦„ì°¨ìˆœ)
    # 2ìˆœìœ„: ë™ì¼ ì‹œê°„ ì°¨ì´ë©´ ê°€ì¥ ìµœê·¼ ë¡œê·¸ (ë‚´ë¦¼ì°¨ìˆœ)
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì •í™•í•œ ì‹œê°„ ë¹„êµ
    def sort_key(x):
        time_diff = x['time_diff']
        try:
            # log_timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
            log_dt = datetime.strptime(x['log_timestamp'], '%Y-%m-%d %H:%M:%S')
            # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ì„ ìœ„í•´ ìŒìˆ˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©
            return (time_diff, -log_dt.timestamp())
        except:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬¸ìì—´ ë¹„êµë¡œ ëŒ€ì²´ (ë‚´ë¦¼ì°¨ìˆœ)
            return (time_diff, -ord(x['log_timestamp'][0]) if x['log_timestamp'] else 0)
    
    matched_patterns.sort(key=sort_key)

    return matched_patterns[0]['pattern_data']


def safe_float(value, default=0.0):
    """ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        # "3.52%" -> 3.52
        # "162,154" -> 162154
        value = value.replace(',', '').replace('%', '').strip()
        try:
            return float(value)
        except:
            return default
    return default


def calculate_avg_volume_from_candles(candles: list) -> float:
    """ìº”ë“¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ê±°ë˜ëŸ‰ ê³„ì‚°"""
    if not candles:
        return 0.0
    volumes = [c.get('volume', 0) for c in candles]
    return sum(volumes) / len(volumes) if volumes else 0.0


def calculate_avg_body_pct(candles: list) -> float:
    """ìº”ë“¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ëª¸í†µ ë¹„ìœ¨ ê³„ì‚°"""
    if not candles:
        return 0.0
    body_pcts = []
    for c in candles:
        open_p = c.get('open', 0)
        close_p = c.get('close', 0)
        if open_p > 0:
            body_pct = abs((close_p - open_p) / open_p * 100)
            body_pcts.append(body_pct)
    return sum(body_pcts) / len(body_pcts) if body_pcts else 0.0


def extract_features_from_pattern(pattern_data: Dict) -> Dict:
    """
    íŒ¨í„´ ë°ì´í„°ì—ì„œ ML íŠ¹ì„± ì¶”ì¶œ (ì‹¤ì œ íŒ¨í„´ íŠ¹ì„± ì‚¬ìš©)
    """
    # ì‹ í˜¸ ì‹œê°„ ì •ë³´
    signal_time_str = pattern_data.get('signal_time', '')
    if signal_time_str:
        try:
            signal_time = datetime.strptime(signal_time_str, '%Y-%m-%d %H:%M:%S')
            hour = signal_time.hour
            minute = signal_time.minute
        except:
            hour, minute = 0, 0
    else:
        hour, minute = 0, 0

    # ì‹ í˜¸ ì •ë³´
    signal_info = pattern_data.get('signal_info', {})
    signal_type = signal_info.get('signal_type', '')
    signal_type_encoded = 1 if signal_type == 'STRONG_BUY' else 0
    confidence = safe_float(signal_info.get('confidence', 0.0))

    # íŒ¨í„´ êµ¬ê°„ ì •ë³´
    pattern_stages = pattern_data.get('pattern_stages', {})

    # ìƒìŠ¹ êµ¬ê°„
    uptrend = pattern_stages.get('1_uptrend', {})
    uptrend_candles = uptrend.get('candle_count', 0)
    uptrend_gain = safe_float(uptrend.get('price_gain', 0.0))
    uptrend_max_volume_str = uptrend.get('max_volume', '0')
    uptrend_max_volume = safe_float(uptrend_max_volume_str)

    # ìƒìŠ¹ êµ¬ê°„ ìº”ë“¤ì—ì„œ í‰ê·  ê³„ì‚°
    uptrend_candles_list = uptrend.get('candles', [])
    uptrend_avg_body = calculate_avg_body_pct(uptrend_candles_list)
    uptrend_total_volume = sum(c.get('volume', 0) for c in uptrend_candles_list)

    # í•˜ë½ êµ¬ê°„
    decline = pattern_stages.get('2_decline', {})
    decline_candles = decline.get('candle_count', 0)
    decline_pct = abs(safe_float(decline.get('decline_pct', 0.0)))
    decline_candles_list = decline.get('candles', [])
    decline_avg_volume = calculate_avg_volume_from_candles(decline_candles_list)

    # ì§€ì§€ êµ¬ê°„
    support = pattern_stages.get('3_support', {})
    support_candles = support.get('candle_count', 0)
    support_volatility = safe_float(support.get('price_volatility', 0.0))
    support_avg_volume_ratio = safe_float(support.get('avg_volume_ratio', 1.0))
    support_candles_list = support.get('candles', [])
    support_avg_volume = calculate_avg_volume_from_candles(support_candles_list)

    # ëŒíŒŒ êµ¬ê°„
    breakout = pattern_stages.get('4_breakout', {})
    if breakout and breakout.get('candle'):
        breakout_candle = breakout.get('candle', {})
        breakout_volume = breakout_candle.get('volume', 0)

        # ëª¸í†µ í¬ê¸° ê³„ì‚°
        open_p = breakout_candle.get('open', 0)
        close_p = breakout_candle.get('close', 0)
        if open_p > 0:
            breakout_body = abs((close_p - open_p) / open_p * 100)
        else:
            breakout_body = 0.0

        # ë²”ìœ„ í¬ê¸° ê³„ì‚°
        high_p = breakout_candle.get('high', 0)
        low_p = breakout_candle.get('low', 0)
        if low_p > 0:
            breakout_range = (high_p - low_p) / low_p * 100
        else:
            breakout_range = 0.0
    else:
        breakout_volume, breakout_body, breakout_range = 0, 0.0, 0.0

    # ë¹„ìœ¨ íŠ¹ì„± ê³„ì‚°
    volume_ratio_decline_to_uptrend = (
        decline_avg_volume / uptrend_max_volume if uptrend_max_volume > 0 else 0
    )
    volume_ratio_support_to_uptrend = (
        support_avg_volume / uptrend_max_volume if uptrend_max_volume > 0 else 0
    )
    volume_ratio_breakout_to_uptrend = (
        breakout_volume / uptrend_max_volume if uptrend_max_volume > 0 else 0
    )
    price_gain_to_decline_ratio = (
        uptrend_gain / decline_pct if decline_pct > 0 else 0
    )
    candle_ratio_support_to_decline = (
        support_candles / decline_candles if decline_candles > 0 else 0
    )

    features = {
        'hour': hour,
        'minute': minute,
        'time_in_minutes': hour * 60 + minute,
        'is_morning': 1 if hour < 12 else 0,

        'signal_type': signal_type_encoded,
        'confidence': confidence,

        'uptrend_candles': uptrend_candles,
        'uptrend_gain': uptrend_gain,
        'uptrend_max_volume': uptrend_max_volume,
        'uptrend_avg_body': uptrend_avg_body,
        'uptrend_total_volume': uptrend_total_volume,

        'decline_candles': decline_candles,
        'decline_pct': decline_pct,
        'decline_avg_volume': decline_avg_volume,

        'support_candles': support_candles,
        'support_volatility': support_volatility,
        'support_avg_volume_ratio': support_avg_volume_ratio,
        'support_avg_volume': support_avg_volume,

        'breakout_volume': breakout_volume,
        'breakout_body': breakout_body,
        'breakout_range': breakout_range,

        'volume_ratio_decline_to_uptrend': volume_ratio_decline_to_uptrend,
        'volume_ratio_support_to_uptrend': volume_ratio_support_to_uptrend,
        'volume_ratio_breakout_to_uptrend': volume_ratio_breakout_to_uptrend,
        'price_gain_to_decline_ratio': price_gain_to_decline_ratio,
        'candle_ratio_support_to_decline': candle_ratio_support_to_decline,
    }

    return features


def predict_win_probability(
    model,
    feature_names,
    signal: Dict,
    pattern_data: Optional[Dict] = None
) -> Tuple[float, str]:
    """
    ì‹ í˜¸ì˜ ìŠ¹ë¥  ì˜ˆì¸¡

    Returns:
        (ìŠ¹ë¥ , ìƒíƒœ ë©”ì‹œì§€)
    """
    try:
        if pattern_data is None:
            return 0.5, "íŒ¨í„´ì—†ìŒ"

        # íŒ¨í„´ ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
        features = extract_features_from_pattern(pattern_data)

        # DataFrameìœ¼ë¡œ ë³€í™˜
        feature_values = [features.get(fname, 0) for fname in feature_names]
        X = pd.DataFrame([feature_values], columns=feature_names)

        # ì˜ˆì¸¡ - ì‹¤ì‹œê°„ ê±°ë˜ì™€ ë™ì¼í•œ ë°©ì‹ (LightGBM predict with best_iteration)
        try:
            # LightGBM Booster ê°ì²´ì¸ ê²½ìš° (ml_model.pkl ë˜ëŠ” ml_model_merged.pkl)
            win_prob = model.predict(
                X.values,
                num_iteration=model.best_iteration
            )[0]
        except (AttributeError, TypeError):
            # sklearn wrapperì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
            try:
                win_prob = model.predict_proba(X)[0][1]
            except:
                win_prob = model.predict(X.values)[0]

        return win_prob, "ì •ìƒ"

    except Exception as e:
        import traceback
        traceback.print_exc()
        return 0.5, f"ì˜¤ë¥˜:{str(e)[:20]}"


def recalculate_statistics(lines: List[str]) -> Dict:
    """
    í•„í„°ë§ëœ ë¼ì¸ì—ì„œ í†µê³„ ì¬ê³„ì‚° (ì£¼ì„ ì²˜ë¦¬ëœ ë¼ì¸ ì œì™¸)

    Returns:
        í†µê³„ ë”•ì…”ë„ˆë¦¬ {total_trades, wins, losses, total_profit, win_profit, loss_amount}
    """
    wins = 0
    losses = 0
    total_profit = 0.0
    win_profit = 0.0
    loss_amount = 0.0

    # ê±°ë˜ ëª©ë¡ ì„¹ì…˜ ì°¾ê¸° (12ì‹œ ì´ì „ ë§¤ìˆ˜ ì¢…ëª© ì„¹ì…˜)
    in_trade_list = False

    for line in lines:
        # ê±°ë˜ ëª©ë¡ ì„¹ì…˜ ì‹œì‘
        if '12ì‹œ ì´ì „ ë§¤ìˆ˜ ì¢…ëª©' in line or 'ğŸŒ…' in line:
            in_trade_list = True
            continue

        # ê±°ë˜ ëª©ë¡ ì„¹ì…˜ ì¢…ë£Œ (ìƒì„¸ ì„¹ì…˜ ì‹œì‘)
        if in_trade_list and line.strip().startswith('===') and ' - ' in line:
            break

        if not in_trade_list:
            continue

        # ì£¼ì„ ì²˜ë¦¬ëœ ë¼ì¸ì€ ì œì™¸
        if line.strip().startswith('#'):
            continue

        # ìŠ¹ë¦¬/íŒ¨ë°° íŒŒì‹±
        win_match = re.search(r'ë§¤ìˆ˜\s+â†’\s+\+([0-9.]+)%', line)
        loss_match = re.search(r'ë§¤ìˆ˜\s+â†’\s+-([0-9.]+)%', line)

        if win_match:
            wins += 1
            profit_pct = float(win_match.group(1))
            profit_amount = 1000000 * profit_pct / 100
            win_profit += profit_amount
            total_profit += profit_amount
        elif loss_match:
            losses += 1
            loss_pct = float(loss_match.group(1))
            loss_amt = 1000000 * loss_pct / 100
            loss_amount += loss_amt
            total_profit -= loss_amt

    return {
        'total_trades': wins + losses,
        'wins': wins,
        'losses': losses,
        'total_profit': total_profit,
        'win_profit': win_profit,
        'loss_amount': loss_amount
    }


def update_statistics_section(lines: List[str], stats: Dict) -> List[str]:
    """
    íŒŒì¼ ìƒë‹¨ì˜ í†µê³„ ì„¹ì…˜ì„ ì—…ë°ì´íŠ¸

    Args:
        lines: ì›ë³¸ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        stats: ì¬ê³„ì‚°ëœ í†µê³„

    Returns:
        ì—…ë°ì´íŠ¸ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
    """
    updated_lines = []
    in_morning_section = False  # 12ì‹œ ì´ì „ ì„¹ì…˜ ì¶”ì 

    for i, line in enumerate(lines):
        # 12ì‹œ ì´ì „ ë§¤ìˆ˜ ì¢…ëª© ì„¹ì…˜ ì‹œì‘
        if '12ì‹œ ì´ì „ ë§¤ìˆ˜ ì¢…ëª©:' in line:
            in_morning_section = True
            win_rate = (stats['wins'] / stats['total_trades'] * 100) if stats['total_trades'] > 0 else 0
            updated_lines.append(
                f"=== ğŸŒ… 12ì‹œ ì´ì „ ë§¤ìˆ˜ ì¢…ëª©: {stats['wins']}ìŠ¹ {stats['losses']}íŒ¨ (ìŠ¹ë¥  {win_rate:.1f}%) ===\n"
            )
        # 12ì‹œ ì´ì „ ì„¹ì…˜ ì¢…ë£Œ (ê±°ë˜ ë¼ì¸ ì‹œì‘)
        elif in_morning_section and (line.strip().startswith('ğŸ”´') or line.strip().startswith('ğŸŸ¢') or line.strip().startswith('#')):
            in_morning_section = False
            updated_lines.append(line)
        # ì´ ê±°ë˜ ë¼ì¸ ì—…ë°ì´íŠ¸
        elif line.startswith('ì´ ê±°ë˜:'):
            updated_lines.append(
                f"ì´ ê±°ë˜: {stats['total_trades']}ê±´ ({stats['wins']}ìŠ¹ {stats['losses']}íŒ¨)\n"
            )
        # ì´ ìˆ˜ìµê¸ˆ ë¼ì¸ ì—…ë°ì´íŠ¸ (ìƒë‹¨ ë° 12ì‹œ ì´ì „ ì„¹ì…˜)
        elif line.startswith('ì´ ìˆ˜ìµê¸ˆ:'):
            profit_rate = (stats['total_profit'] / (stats['total_trades'] * 1000000) * 100) if stats['total_trades'] > 0 else 0
            updated_lines.append(
                f"ì´ ìˆ˜ìµê¸ˆ: {stats['total_profit']:+,.0f}ì› ({profit_rate:+.1f}%)\n"
            )
        # ìŠ¹ë¦¬ ìˆ˜ìµ ë¼ì¸ ì—…ë°ì´íŠ¸
        elif 'ìŠ¹ë¦¬ ìˆ˜ìµ:' in line:
            updated_lines.append(
                f"  ã„´ ìŠ¹ë¦¬ ìˆ˜ìµ: {stats['win_profit']:+,.0f}ì› (ì‹¤ì œ ìˆ˜ìµë¥  í•©ê³„)\n"
            )
        # ì†ì‹¤ ê¸ˆì•¡ ë¼ì¸ ì—…ë°ì´íŠ¸
        elif 'ì†ì‹¤ ê¸ˆì•¡:' in line:
            updated_lines.append(
                f"  ã„´ ì†ì‹¤ ê¸ˆì•¡: {-stats['loss_amount']:+,.0f}ì› (ì‹¤ì œ ì†ì‹¤ë¥  í•©ê³„)\n"
            )
        # ì´ ìŠ¹íŒ¨ ë¼ì¸ ì—…ë°ì´íŠ¸
        elif line.startswith('=== ì´ ìŠ¹íŒ¨:'):
            updated_lines.append(
                f"=== ì´ ìŠ¹íŒ¨: {stats['wins']}ìŠ¹ {stats['losses']}íŒ¨ ===\n"
            )
        # selection_date ì´í›„ ìŠ¹íŒ¨ ë¼ì¸ ì—…ë°ì´íŠ¸
        elif line.startswith('=== selection_date ì´í›„ ìŠ¹íŒ¨:'):
            updated_lines.append(
                f"=== selection_date ì´í›„ ìŠ¹íŒ¨: {stats['wins']}ìŠ¹ {stats['losses']}íŒ¨ ===\n"
            )
        else:
            updated_lines.append(line)

    return updated_lines


def apply_ml_filter_to_file(
    input_file: str,
    output_file: str,
    model,
    feature_names,
    threshold: float = 0.5
) -> Tuple[int, int]:
    """
    ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì¼ì— ML í•„í„° ì ìš©

    Returns:
        (ì´ ì‹ í˜¸ ìˆ˜, í•„í„°ë§ëœ ì‹ í˜¸ ìˆ˜)
    """
    print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {input_file}")

    # ì¢…ëª©ëª… ë§¤í•‘ ë¡œë“œ
    stock_names = load_stock_names()

    # ë‚ ì§œ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
    # ì˜ˆ: signal_replay_log_ml/signal_replay_20251103_9_00_0_temp.txt
    input_path = Path(input_file)
    filename = input_path.stem  # signal_replay_20251103_9_00_0_temp

    # ë‚ ì§œ ì¶”ì¶œ (YYYYMMDD í˜•ì‹)
    date_match = re.search(r'(\d{8})', filename)
    if date_match:
        date_str = date_match.group(1)
        patterns = load_pattern_data_for_date(date_str)
    else:
        print("   âš ï¸  ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´ ë°ì´í„° ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        patterns = {}

    with open(input_file, 'r', encoding='utf-8-sig') as f:
        lines = f.readlines()

    output_lines = []
    total_signals = 0
    filtered_signals = 0
    no_pattern_count = 0

    for line in lines:
        # ì‹ í˜¸ ë¼ì¸ì¸ì§€ í™•ì¸
        signal = parse_signal_from_log_line(line)

        if signal:
            total_signals += 1
            stock_code = signal['stock_code']
            stock_name = stock_names.get(stock_code, '???')

            # íŒ¨í„´ ë°ì´í„° ì°¾ê¸°
            pattern_data = find_matching_pattern(patterns, signal) if patterns else None

            # ML ì˜ˆì¸¡
            win_prob, status = predict_win_probability(model, feature_names, signal, pattern_data)

            if status == "íŒ¨í„´ì—†ìŒ":
                no_pattern_count += 1

            # ê¸°ì¡´ ë¼ì¸ì—ì„œ ì¢…ëª© ì½”ë“œ ë¶€ë¶„ì„ "ì½”ë“œ(ì¢…ëª©ëª…)" í˜•ì‹ìœ¼ë¡œ êµì²´
            # ì˜ˆ: "   ğŸŸ¢ 174900 09:21 ë§¤ìˆ˜ â†’ +3.50%" -> "   ğŸŸ¢ 174900(ì½”ìŠ¤ë§¥ìŠ¤) 09:21 ë§¤ìˆ˜ â†’ +3.50%"
            # ì •ê·œì‹ ê·¸ë£¹ ì°¸ì¡° ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ replace ì‚¬ìš©
            pattern = re.search(r'([ğŸ”´ğŸŸ¢]\s+)' + stock_code + r'(\s+)', line)
            if pattern:
                modified_line = line[:pattern.start()] + pattern.group(1) + f"{stock_code}({stock_name})" + pattern.group(2) + line[pattern.end():].rstrip()
            else:
                modified_line = line.rstrip()

            # ì„ê³„ê°’ ì´ìƒë§Œ í†µê³¼
            if win_prob >= threshold:
                # ì˜ˆì¸¡ ìŠ¹ë¥  ì¶”ê°€
                modified_line += f" [ML: {win_prob:.1%}]"
                if status != "ì •ìƒ":
                    modified_line += f" ({status})"
                modified_line += "\n"
                output_lines.append(modified_line)
            else:
                filtered_signals += 1
                # í•„í„°ë§ëœ ì‹ í˜¸ëŠ” ì£¼ì„ ì²˜ë¦¬
                comment = f"# [ML í•„í„°ë§: {win_prob:.1%}"
                if status != "ì •ìƒ":
                    comment += f" ({status})"
                comment += f"]    {modified_line}\n"
                output_lines.append(comment)
        else:
            # ì‹ í˜¸ê°€ ì•„ë‹Œ ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
            output_lines.append(line)

    # í†µê³„ ì¬ê³„ì‚°
    print(f"\n   ğŸ“Š í†µê³„ ì¬ê³„ì‚° ì¤‘...")
    recalc_stats = recalculate_statistics(output_lines)

    # í†µê³„ ì„¹ì…˜ ì—…ë°ì´íŠ¸
    output_lines = update_statistics_section(output_lines, recalc_stats)

    # í•„í„°ë§ëœ ê²°ê³¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8-sig') as f:
        f.writelines(output_lines)

    print(f"\n   í•„í„°ë§ ì „ ì‹ í˜¸: {total_signals}ê°œ")
    print(f"   í•„í„°ë§ í›„ ì‹ í˜¸: {total_signals - filtered_signals}ê°œ")
    print(f"   ì°¨ë‹¨: {filtered_signals}ê°œ ({filtered_signals/total_signals*100 if total_signals > 0 else 0:.1f}%)")
    if no_pattern_count > 0:
        print(f"   íŒ¨í„´ì—†ìŒ: {no_pattern_count}ê°œ ({no_pattern_count/total_signals*100 if total_signals > 0 else 0:.1f}%)")

    print(f"\n   ğŸ“ˆ í•„í„°ë§ í›„ í†µê³„:")
    print(f"   ì´ ê±°ë˜: {recalc_stats['total_trades']}ê±´ ({recalc_stats['wins']}ìŠ¹ {recalc_stats['losses']}íŒ¨)")
    win_rate = (recalc_stats['wins'] / recalc_stats['total_trades'] * 100) if recalc_stats['total_trades'] > 0 else 0
    print(f"   ìŠ¹ë¥ : {win_rate:.1f}%")
    print(f"   ì´ ìˆ˜ìµ: {recalc_stats['total_profit']:+,.0f}ì›")

    return total_signals, filtered_signals


def main():
    import argparse

    parser = argparse.ArgumentParser(description="ë³‘í•© ML ëª¨ë¸ë¡œ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•„í„°ë§")
    parser.add_argument('input_file', help="ì…ë ¥ íŒŒì¼ (signal_replay ê²°ê³¼)")
    parser.add_argument('--output', '-o', help="ì¶œë ¥ íŒŒì¼ (ê¸°ë³¸: ì…ë ¥íŒŒì¼ì— _ml_filtered ì¶”ê°€)")
    parser.add_argument('--threshold', '-t', type=float, default=0.6, help="ìŠ¹ë¥  ì„ê³„ê°’ (ê¸°ë³¸: 0.6, ë³‘í•© ëª¨ë¸ ìµœì ê°’)")
    parser.add_argument('--model', '-m', default="ml_model_merged.pkl", help="ML ëª¨ë¸ íŒŒì¼")

    args = parser.parse_args()

    # ì¶œë ¥ íŒŒì¼ëª… ê²°ì •
    if args.output:
        output_file = args.output
    else:
        input_path = Path(args.input_file)
        output_file = str(input_path.parent / f"{input_path.stem}_ml_filtered{input_path.suffix}")

    print("=" * 70)
    print("ğŸ¤– ML í•„í„° ì ìš©")
    print("=" * 70)
    print(f"ì…ë ¥: {args.input_file}")
    print(f"ì¶œë ¥: {output_file}")
    print(f"ì„ê³„ê°’: {args.threshold:.1%}")

    # ML ëª¨ë¸ ë¡œë“œ
    model, feature_names = load_ml_model(args.model)

    if model is None:
        print("\nâŒ ML ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í•„í„°ë§ ì ìš©
    total, filtered = apply_ml_filter_to_file(
        args.input_file,
        output_file,
        model,
        feature_names,
        args.threshold
    )

    print("\n" + "=" * 70)
    print(f"âœ… ì™„ë£Œ: {output_file}")
    print("=" * 70)


if __name__ == "__main__":
    main()
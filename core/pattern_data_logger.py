"""
4ë‹¨ê³„ íŒ¨í„´ êµ¬ê°„ ë°ì´í„° ë¡œê±°
ê° êµ¬ê°„(ìƒìŠ¹, í•˜ë½, ì§€ì§€, ëŒíŒŒ)ì˜ ìƒì„¸ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
"""

import json
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional


class PatternDataLogger:
    """4ë‹¨ê³„ íŒ¨í„´ êµ¬ê°„ ë°ì´í„° ë¡œê¹…"""

    def __init__(self, log_dir: str = "pattern_data_log", simulation_date: Optional[str] = None):
        """
        Args:
            log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            simulation_date: ì‹œë®¬ë ˆì´ì…˜ ë‚ ì§œ (YYYYMMDD í˜•ì‹, Noneì´ë©´ ì‹¤ì‹œê°„ ë‚ ì§œ ì‚¬ìš©)
        """
        # â­ ë™ì  ì†ìµë¹„ ì„¤ì •ì— ë”°ë¼ ë‹¤ë¥¸ í´ë” ì‚¬ìš©
        from config.dynamic_profit_loss_config import DynamicProfitLossConfig

        if DynamicProfitLossConfig.is_dynamic_enabled():
            # ë™ì  ì†ìµë¹„ ì‚¬ìš© ì‹œ ë³„ë„ í´ë”
            if log_dir == "pattern_data_log":
                log_dir = "pattern_data_log_dynamic"

        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)

        # ë‚ ì§œë³„ ë¡œê·¸ íŒŒì¼ (ì‹œë®¬ë ˆì´ì…˜ ë‚ ì§œ ë˜ëŠ” ì‹¤ì‹œê°„ ë‚ ì§œ)
        if simulation_date:
            today = simulation_date
        else:
            today = datetime.now().strftime('%Y%m%d')
        self.log_file = self.log_dir / f"pattern_data_{today}.jsonl"

        # ğŸ†• ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê¸°ì¡´ íŒ¨í„´ ID ë¡œë“œ
        self.existing_pattern_ids = self._load_existing_pattern_ids()

    def log_pattern_data(
        self,
        stock_code: str,
        signal_type: str,
        confidence: float,
        support_pattern_info: Dict[str, Any],
        data_3min: pd.DataFrame,
        data_1min: Optional[pd.DataFrame] = None  # ğŸ†• 1ë¶„ë´‰ ë°ì´í„° ì¶”ê°€
    ) -> str:
        """
        4ë‹¨ê³„ íŒ¨í„´ êµ¬ê°„ ë°ì´í„° ë¡œê¹…

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            signal_type: ì‹ í˜¸ íƒ€ì… (STRONG_BUY, CAUTIOUS_BUY ë“±)
            confidence: ì‹ ë¢°ë„
            support_pattern_info: analyze_support_pattern í•¨ìˆ˜ì˜ ë¦¬í„´ê°’
            data_3min: 3ë¶„ë´‰ ë°ì´í„°
            data_1min: 1ë¶„ë´‰ ë°ì´í„° (ë§¤ìˆ˜ ì‹œì  ìŠ¤ëƒ…ìƒ· ë° ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ìš©)

        Returns:
            pattern_id: íŒ¨í„´ ê³ ìœ  ID
        """
        # ğŸ†• ë§¤ìˆ˜ ì‹œì  íƒ€ì„ìŠ¤íƒ¬í”„ (ì‹¤ì œ ì‹ í˜¸ ë°œìƒ ì‹œì )
        # support_pattern_infoì— signal_timeì´ ìˆìœ¼ë©´ ì‚¬ìš© (ì‹¤ì‹œê°„ì—ì„œ ì „ë‹¬ë¨)
        if 'signal_time' in support_pattern_info:
            signal_time_str = support_pattern_info['signal_time']
            try:
                signal_time = pd.to_datetime(signal_time_str)
            except:
                signal_time = datetime.now()
        else:
            # ì‹œë®¬ë ˆì´ì…˜: ë§ˆì§€ë§‰ 3ë¶„ë´‰ì˜ ì™„ì„± ì‹œì  ì‚¬ìš©
            if data_3min is not None and len(data_3min) > 0:
                last_candle_time = data_3min.iloc[-1]['datetime']
                # 3ë¶„ë´‰ ì‹œì‘ ì‹œê°„ì— 3ë¶„ì„ ë”í•´ ì™„ì„± ì‹œì  ê³„ì‚°
                signal_time = last_candle_time + pd.Timedelta(minutes=3)
            else:
                signal_time = datetime.now()

        # íŒ¨í„´ ê³ ìœ  ID ìƒì„± (ë§¤ìˆ˜ ì‹œì  ê¸°ì¤€)
        pattern_id = f"{stock_code}_{signal_time.strftime('%Y%m%d_%H%M%S')}"

        # ë””ë²„ê·¸ ì •ë³´ ì¶”ì¶œ
        debug_info = support_pattern_info.get('debug_info', {})

        # 4ê°œ êµ¬ê°„ ë°ì´í„° ì¶”ì¶œ
        uptrend_info = debug_info.get('uptrend', {})
        decline_info = debug_info.get('decline', {})
        support_info = debug_info.get('support', {})
        breakout_info = debug_info.get('breakout', {})

        # ê° êµ¬ê°„ì˜ ìº”ë“¤ ë°ì´í„° ì¶”ì¶œ
        uptrend_candles = self._extract_candle_data(
            data_3min,
            uptrend_info.get('start_idx'),
            uptrend_info.get('end_idx')
        ) if uptrend_info else []

        decline_candles = self._extract_candle_data(
            data_3min,
            decline_info.get('start_idx'),
            decline_info.get('end_idx')
        ) if decline_info else []

        support_candles = self._extract_candle_data(
            data_3min,
            support_info.get('start_idx'),
            support_info.get('end_idx')
        ) if support_info else []

        breakout_candle = self._extract_single_candle(
            data_3min,
            breakout_info.get('idx')
        ) if breakout_info else None

        # breakout_idx ì¶”ì¶œ (ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ìš©)
        breakout_idx = breakout_info.get('idx') if breakout_info else None

        # ğŸ†• ë§¤ìˆ˜ ì‹œì ì˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (3ë¶„ë´‰ ê¸°ì¤€)
        technical_indicators_3min = {}
        if breakout_idx is not None:
            technical_indicators_3min = self._calculate_technical_indicators(data_3min, breakout_idx)

        # ğŸ†• 1ë¶„ë´‰ ê¸°ë°˜ ìƒì„¸ ì§€í‘œ (1ë¶„ë´‰ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
        technical_indicators_1min = {}
        lookback_sequence_1min = []
        if data_1min is not None and not data_1min.empty:
            # 1ë¶„ë´‰ì—ì„œ ì‹ í˜¸ ì‹œì  ì°¾ê¸°
            signal_1min_data = data_1min[data_1min['datetime'] <= signal_time]
            if not signal_1min_data.empty:
                signal_1min_idx = len(signal_1min_data) - 1
                technical_indicators_1min = self._calculate_technical_indicators(data_1min, signal_1min_idx)

                # 1ì‹œê°„ lookback ì‹œí€€ìŠ¤ (60ê°œ 1ë¶„ë´‰)
                lookback_sequence_1min = self._extract_lookback_sequence(
                    data_1min,
                    signal_time,
                    lookback_minutes=60
                )

        # ë¡œê·¸ ë ˆì½”ë“œ ìƒì„±
        log_record = {
            'pattern_id': pattern_id,
            'signal_time': signal_time.strftime('%Y-%m-%d %H:%M:%S'),  # ğŸ†• ë§¤ìˆ˜ ì‹ í˜¸ ì‹œê°„
            'log_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # ğŸ†• ë¡œê¹… ì‹œê°„ (êµ¬ë¶„)
            'stock_code': stock_code,
            'signal_info': {
                'signal_type': signal_type,
                'confidence': float(confidence) if confidence is not None else 0.0,
                'has_pattern': support_pattern_info.get('has_support_pattern', False),
                'reasons': support_pattern_info.get('reasons', []),
                'ml_prob': support_pattern_info.get('ml_prob', None)  # ğŸ†• ML ì˜ˆì¸¡ê°’ ì¶”ê°€
            },
            # ğŸ†• ë§¤ìˆ˜ ì‹œì  ìŠ¤ëƒ…ìƒ·
            'signal_snapshot': {
                'technical_indicators_3min': technical_indicators_3min,
                'technical_indicators_1min': technical_indicators_1min,
                'lookback_sequence_1min': lookback_sequence_1min  # ê³¼ê±° 60ë¶„ 1ë¶„ë´‰ ì‹œí€€ìŠ¤
            },
            'pattern_stages': {
                '1_uptrend': {
                    'start_idx': uptrend_info.get('start_idx'),
                    'end_idx': uptrend_info.get('end_idx'),
                    'candle_count': len(uptrend_candles),
                    # ğŸ”„ ìˆ«ìí˜• í•„ë“œ ìš°ì„  ì‚¬ìš© (gain_pct, max_volume_numeric), ì—†ìœ¼ë©´ ë¬¸ìì—´ ë³€í™˜
                    'max_volume': self._safe_float(uptrend_info.get('max_volume_numeric', uptrend_info.get('max_volume'))),
                    'volume_avg': self._safe_float(uptrend_info.get('avg_volume', uptrend_info.get('volume_avg'))),
                    'max_volume_ratio_vs_avg': self._safe_float(uptrend_info.get('max_volume_ratio_vs_avg')),
                    'price_gain': self._safe_float(uptrend_info.get('gain_pct', uptrend_info.get('price_gain'))),
                    'high_price': self._safe_float(uptrend_info.get('high_price')),
                    'candles': uptrend_candles
                },
                '2_decline': {
                    'start_idx': decline_info.get('start_idx'),
                    'end_idx': decline_info.get('end_idx'),
                    'candle_count': len(decline_candles),
                    # ğŸ”„ decline_pctëŠ” ë¬¸ìì—´ë¡œ ì˜¬ ìˆ˜ ìˆìŒ (ì˜ˆ: "2.73%")
                    'decline_pct': self._safe_float(decline_info.get('decline_pct')),
                    'max_decline_price': self._safe_float(decline_info.get('max_decline_price')),
                    'avg_volume_ratio': self._safe_float(decline_info.get('avg_volume_ratio')),
                    # MLìš© ì¶”ê°€ í†µê³„
                    'avg_volume': self._safe_float(decline_info.get('avg_volume')),
                    'candles': decline_candles
                },
                '3_support': {
                    'start_idx': support_info.get('start_idx'),
                    'end_idx': support_info.get('end_idx'),
                    'candle_count': len(support_candles),
                    'support_price': self._safe_float(support_info.get('support_price')),
                    'price_volatility': self._safe_float(support_info.get('price_volatility')),
                    'avg_volume_ratio': self._safe_float(support_info.get('avg_volume_ratio')),
                    # MLìš© ì¶”ê°€ í†µê³„
                    'avg_volume': self._safe_float(support_info.get('avg_volume')),
                    'candles': support_candles
                },
                '4_breakout': {
                    'idx': breakout_info.get('idx'),
                    'body_size': self._safe_float(breakout_info.get('body_size')),
                    'volume': self._safe_float(breakout_info.get('volume')),
                    'volume_ratio_vs_prev': self._safe_float(breakout_info.get('volume_ratio_vs_prev')),
                    'body_increase_vs_support': self._safe_float(breakout_info.get('body_increase_vs_support')),
                    'candle': breakout_candle
                }
            },
            'trade_result': None  # ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
        }

        # ğŸ†• ì¤‘ë³µ ì²´í¬
        if pattern_id in self.existing_pattern_ids:
            print(f"[ìŠ¤í‚µ] ì¤‘ë³µ íŒ¨í„´ ID: {pattern_id}")
            return pattern_id

        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥ (íŒŒì¼ ì ê¸ˆ ë° ì˜ˆì™¸ ì²˜ë¦¬)
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                json_str = json.dumps(log_record, ensure_ascii=False)
                # JSONì´ ìœ íš¨í•œì§€ í•œë²ˆ ë” ê²€ì¦
                json.loads(json_str)  # íŒŒì‹± í…ŒìŠ¤íŠ¸
                f.write(json_str + '\n')
                f.flush()  # ì¦‰ì‹œ ë””ìŠ¤í¬ì— ì“°ê¸°

            # ğŸ†• ì €ì¥ ì„±ê³µ ì‹œ ë©”ëª¨ë¦¬ì— ì¶”ê°€
            self.existing_pattern_ids.add(pattern_id)

        except Exception as e:
            # ë¡œê¹… ì‹¤íŒ¨í•´ë„ íŒ¨í„´ IDëŠ” ë°˜í™˜ (ì‹œë®¬ë ˆì´ì…˜ ê³„ì† ì§„í–‰)
            print(f"[ê²½ê³ ] íŒ¨í„´ ë°ì´í„° ë¡œê¹… ì‹¤íŒ¨ ({pattern_id}): {e}")

        return pattern_id

    def _safe_float(self, value, default=0.0):
        """ë¬¸ìì—´ ë˜ëŠ” ìˆ«ìë¥¼ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
        if value is None:
            return default
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            # ì‰¼í‘œì™€ í¼ì„¼íŠ¸ ê¸°í˜¸ ì œê±°
            value = value.replace(',', '').replace('%', '').strip()
            try:
                return float(value)
            except:
                return default
        return default

    def _extract_candle_data(self, data: pd.DataFrame, start_idx: Optional[int], end_idx: Optional[int]) -> list:
        """êµ¬ê°„ì˜ ìº”ë“¤ ë°ì´í„° ì¶”ì¶œ"""
        if start_idx is None or end_idx is None:
            return []

        try:
            candles = []
            for idx in range(start_idx, end_idx + 1):
                if idx < len(data):
                    row = data.iloc[idx]
                    candle = {
                        'datetime': row['datetime'].strftime('%Y-%m-%d %H:%M:%S') if pd.notna(row.get('datetime')) else str(idx),
                        'open': float(row['open']) if pd.notna(row['open']) else 0.0,
                        'high': float(row['high']) if pd.notna(row['high']) else 0.0,
                        'low': float(row['low']) if pd.notna(row['low']) else 0.0,
                        'close': float(row['close']) if pd.notna(row['close']) else 0.0,
                        'volume': int(float(row['volume'])) if pd.notna(row['volume']) else 0
                    }
                    candles.append(candle)
            return candles
        except Exception as e:
            print(f"ìº”ë“¤ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    def _extract_single_candle(self, data: pd.DataFrame, idx: Optional[int]) -> Optional[dict]:
        """ë‹¨ì¼ ìº”ë“¤ ë°ì´í„° ì¶”ì¶œ"""
        if idx is None or idx >= len(data):
            return None

        try:
            row = data.iloc[idx]
            return {
                'datetime': row['datetime'].strftime('%Y-%m-%d %H:%M:%S') if pd.notna(row.get('datetime')) else str(idx),
                'open': float(row['open']) if pd.notna(row['open']) else 0.0,
                'high': float(row['high']) if pd.notna(row['high']) else 0.0,
                'low': float(row['low']) if pd.notna(row['low']) else 0.0,
                'close': float(row['close']) if pd.notna(row['close']) else 0.0,
                'volume': int(float(row['volume'])) if pd.notna(row['volume']) else 0
            }
        except Exception as e:
            print(f"ìº”ë“¤ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def _calculate_technical_indicators(self, data: pd.DataFrame, signal_idx: int) -> Dict[str, float]:
        """
        ë§¤ìˆ˜ ì‹œì ì˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°

        Args:
            data: ë¶„ë´‰ ë°ì´í„° (3ë¶„ë´‰ ë˜ëŠ” 1ë¶„ë´‰)
            signal_idx: ì‹ í˜¸ ë°œìƒ ì¸ë±ìŠ¤

        Returns:
            ê¸°ìˆ ì  ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        """
        indicators = {}

        try:
            # ì‹ í˜¸ ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
            data_until_signal = data.iloc[:signal_idx+1].copy()

            if len(data_until_signal) < 14:
                return indicators  # ë°ì´í„° ë¶€ì¡±

            # RSI ê³„ì‚° (14ë´‰)
            close_prices = data_until_signal['close'].values
            rsi = self._calculate_rsi(close_prices, period=14)
            indicators['rsi_14'] = rsi

            # ì´ë™í‰ê·  ê³„ì‚°
            ma_5 = close_prices[-5:].mean() if len(close_prices) >= 5 else close_prices[-1]
            ma_10 = close_prices[-10:].mean() if len(close_prices) >= 10 else close_prices[-1]
            ma_20 = close_prices[-20:].mean() if len(close_prices) >= 20 else close_prices[-1]

            indicators['ma_5'] = float(ma_5)
            indicators['ma_10'] = float(ma_10)
            indicators['ma_20'] = float(ma_20)

            # í˜„ì¬ê°€ ëŒ€ë¹„ ì´ë™í‰ê·  ìœ„ì¹˜ (%)
            current_price = close_prices[-1]
            indicators['price_vs_ma5_pct'] = ((current_price - ma_5) / ma_5 * 100) if ma_5 > 0 else 0
            indicators['price_vs_ma20_pct'] = ((current_price - ma_20) / ma_20 * 100) if ma_20 > 0 else 0

            # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
            volumes = data_until_signal['volume'].values
            volume_ma_20 = volumes[-20:].mean() if len(volumes) >= 20 else volumes[-1]
            current_volume = volumes[-1]
            indicators['volume_ma_20'] = float(volume_ma_20)
            indicators['volume_vs_ma_ratio'] = (current_volume / volume_ma_20) if volume_ma_20 > 0 else 1.0

            # ATR (í‰ê·  ì§„í­) - 14ë´‰
            if len(data_until_signal) >= 14:
                atr = self._calculate_atr(data_until_signal, period=14)
                indicators['atr_14'] = atr
                indicators['atr_pct'] = (atr / current_price * 100) if current_price > 0 else 0

        except Exception as e:
            print(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")

        return indicators

    def _calculate_rsi(self, prices: 'np.ndarray', period: int = 14) -> float:
        """RSI ê³„ì‚°"""
        try:
            import numpy as np

            if len(prices) < period + 1:
                return 50.0  # ê¸°ë³¸ê°’

            deltas = np.diff(prices)
            gains = np.where(deltas > 0, deltas, 0)
            losses = np.where(deltas < 0, -deltas, 0)

            avg_gain = gains[-period:].mean()
            avg_loss = losses[-period:].mean()

            if avg_loss == 0:
                return 100.0

            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))

            return float(rsi)
        except Exception:
            return 50.0

    def _calculate_atr(self, data: pd.DataFrame, period: int = 14) -> float:
        """ATR (Average True Range) ê³„ì‚°"""
        try:
            import numpy as np

            if len(data) < period + 1:
                return 0.0

            high = data['high'].values
            low = data['low'].values
            close = data['close'].values

            # True Range ê³„ì‚°
            tr1 = high[1:] - low[1:]  # ê³ ê°€ - ì €ê°€
            tr2 = np.abs(high[1:] - close[:-1])  # ê³ ê°€ - ì „ì¼ì¢…ê°€
            tr3 = np.abs(low[1:] - close[:-1])   # ì €ê°€ - ì „ì¼ì¢…ê°€

            tr = np.maximum(tr1, np.maximum(tr2, tr3))

            # ATR = TRì˜ ì´ë™í‰ê· 
            atr = tr[-period:].mean() if len(tr) >= period else tr.mean()

            return float(atr)
        except Exception:
            return 0.0

    def _extract_lookback_sequence(
        self,
        data: pd.DataFrame,
        signal_time: datetime,
        lookback_minutes: int = 60
    ) -> list:
        """
        ë§¤ìˆ˜ ì‹œì  ì´ì „ Në¶„ê°„ì˜ ë¶„ë´‰ ì‹œí€€ìŠ¤ ì¶”ì¶œ

        Args:
            data: 1ë¶„ë´‰ ë˜ëŠ” 3ë¶„ë´‰ ë°ì´í„°
            signal_time: ë§¤ìˆ˜ ì‹ í˜¸ ë°œìƒ ì‹œê°„
            lookback_minutes: ê³¼ê±° ëª‡ ë¶„ì„ ë³¼ì§€ (ê¸°ë³¸ 60ë¶„ = 1ì‹œê°„)

        Returns:
            ë¶„ë´‰ OHLCV ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì‹ í˜¸ ì‹œì  ì´ì „ ë°ì´í„°ë§Œ í•„í„°ë§
            data_before_signal = data[data['datetime'] <= signal_time].copy()

            if data_before_signal.empty:
                return []

            # ìµœê·¼ Nê°œ ìº”ë“¤ ì¶”ì¶œ (1ë¶„ë´‰ì´ë©´ 60ê°œ, 3ë¶„ë´‰ì´ë©´ 20ê°œ)
            candle_interval = 1 if 'datetime' in data_before_signal.columns else 3
            lookback_count = lookback_minutes // candle_interval

            recent_data = data_before_signal.tail(lookback_count)

            # OHLCV ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
            sequence = []
            for _, row in recent_data.iterrows():
                candle = {
                    'datetime': row['datetime'].strftime('%Y-%m-%d %H:%M:%S') if pd.notna(row.get('datetime')) else '',
                    'open': float(row['open']) if pd.notna(row['open']) else 0.0,
                    'high': float(row['high']) if pd.notna(row['high']) else 0.0,
                    'low': float(row['low']) if pd.notna(row['low']) else 0.0,
                    'close': float(row['close']) if pd.notna(row['close']) else 0.0,
                    'volume': int(float(row['volume'])) if pd.notna(row['volume']) else 0
                }
                sequence.append(candle)

            return sequence
        except Exception as e:
            print(f"ë¶„ë´‰ ì‹œí€€ìŠ¤ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    def _analyze_post_trade_trajectory(self, trade_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ ê°€ê²© ê¶¤ì  ë¶„ì„

        Args:
            trade_data: ë§¤ë§¤ ìƒì„¸ ë°ì´í„°

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            import numpy as np
            import pandas as pd

            buy_price = trade_data.get('buy_price', 0)
            sell_price = trade_data.get('sell_price', 0)
            buy_time = trade_data.get('buy_time')
            sell_time = trade_data.get('sell_time')
            df_1min = trade_data.get('df_1min_during_trade')

            if buy_price == 0 or df_1min is None or df_1min.empty:
                return {}

            # ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ 1ë¶„ë´‰ë§Œ ì¶”ì¶œ
            trade_candles = df_1min[
                (df_1min['datetime'] > buy_time) &
                (df_1min['datetime'] <= sell_time)
            ].copy()

            if trade_candles.empty:
                return {}

            # ì‹œê°„ëŒ€ë³„ ìˆ˜ìµë¥  ê¶¤ì 
            trajectory = []
            checkpoints = [5, 10, 30, 60, 120]  # 5ë¶„, 10ë¶„, 30ë¶„, 1ì‹œê°„, 2ì‹œê°„

            for minutes in checkpoints:
                # ë§¤ìˆ˜ í›„ Në¶„ê¹Œì§€ì˜ ë°ì´í„°
                cutoff_time = buy_time + pd.Timedelta(minutes=minutes)
                candles_until = trade_candles[trade_candles['datetime'] <= cutoff_time]

                if candles_until.empty:
                    continue

                max_high = candles_until['high'].max()
                min_low = candles_until['low'].min()

                max_profit = ((max_high - buy_price) / buy_price) * 100
                max_loss = ((min_low - buy_price) / buy_price) * 100

                trajectory.append({
                    'minutes_after': minutes,
                    'max_profit': round(max_profit, 2),
                    'max_loss': round(max_loss, 2)
                })

            # ìµœê³ /ìµœì € ìˆ˜ìµë¥  ì‹œì  ì°¾ê¸°
            all_highs = trade_candles['high'].values
            all_lows = trade_candles['low'].values
            all_times = trade_candles['datetime'].values

            profit_rates = ((all_highs - buy_price) / buy_price) * 100
            loss_rates = ((all_lows - buy_price) / buy_price) * 100

            peak_idx = np.argmax(profit_rates)
            worst_idx = np.argmin(loss_rates)

            peak_profit_rate = profit_rates[peak_idx]
            worst_drawdown = loss_rates[worst_idx]

            # ì‹œì  ê³„ì‚° (ë§¤ìˆ˜ í›„ ëª‡ ë¶„)
            peak_time = all_times[peak_idx]
            worst_time = all_times[worst_idx]

            peak_minutes = int((peak_time - buy_time).total_seconds() / 60)
            worst_minutes = int((worst_time - buy_time).total_seconds() / 60)

            # ê±°ë˜ëŸ‰ íŒ¨í„´ ë¶„ì„
            volumes = trade_candles['volume'].values
            volume_at_peak = trade_candles.iloc[peak_idx]['volume']
            volume_at_worst = trade_candles.iloc[worst_idx]['volume']
            avg_volume = volumes.mean()

            # ë§¤ìˆ˜ ì§í›„ (ì²« 5ë¶„) ê±°ë˜ëŸ‰ ê¸‰ì¦ ì—¬ë¶€
            first_5min = trade_candles.head(5) if len(trade_candles) >= 5 else trade_candles
            immediate_volume = first_5min['volume'].mean()
            immediate_volume_spike = (immediate_volume / avg_volume) if avg_volume > 0 else 1.0

            analysis = {
                # ê°€ê²© ê¶¤ì 
                'profit_trajectory': trajectory,

                # ì£¼ìš” ì´ë²¤íŠ¸
                'peak_profit_reached_at': peak_minutes,
                'peak_profit_rate': round(peak_profit_rate, 2),
                'worst_drawdown': round(worst_drawdown, 2),
                'worst_drawdown_at': worst_minutes,

                # ë§¤ë„ ì •ë³´
                'holding_duration_minutes': int((sell_time - buy_time).total_seconds() / 60),
                'final_profit_rate': round(((sell_price - buy_price) / buy_price) * 100, 2),

                # ê±°ë˜ëŸ‰ íŒ¨í„´
                'volume_pattern': {
                    'immediate_spike_ratio': round(immediate_volume_spike, 2),
                    'avg_volume_during_trade': int(avg_volume),
                    'volume_at_peak': int(volume_at_peak),
                    'volume_at_worst': int(volume_at_worst)
                },

                # ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ 1ë¶„ë´‰ ì €ì¥ (ì„ íƒì‚¬í•­ - ìš©ëŸ‰ ê³ ë ¤)
                # 'trade_candles': trade_candles.to_dict('records')  # í•„ìš”ì‹œ í™œì„±í™”
            }

            return analysis

        except Exception as e:
            print(f"ê°€ê²© ê¶¤ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}

    def update_trade_result(
        self,
        pattern_id: str,
        trade_executed: bool,
        profit_rate: Optional[float] = None,
        sell_reason: Optional[str] = None,
        trade_data: Optional[Dict[str, Any]] = None  # ğŸ†• ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ ë°ì´í„°
    ):
        """
        ë§¤ë§¤ ê²°ê³¼ ì—…ë°ì´íŠ¸

        Args:
            pattern_id: íŒ¨í„´ ê³ ìœ  ID
            trade_executed: ê±°ë˜ ì‹¤í–‰ ì—¬ë¶€
            profit_rate: ìˆ˜ìµë¥ 
            sell_reason: ë§¤ë„ ì‚¬ìœ 
            trade_data: ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ ìƒì„¸ ë°ì´í„° (ì˜µì…˜)
                {
                    'buy_time': datetime,
                    'sell_time': datetime,
                    'buy_price': float,
                    'sell_price': float,
                    'max_profit_rate': float,
                    'max_loss_rate': float,
                    'duration_minutes': int,
                    'df_1min_during_trade': DataFrame  # ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ 1ë¶„ë´‰
                }
        """
        if not self.log_file.exists():
            return

        try:
            # ì „ì²´ ë¡œê·¸ ì½ê¸° (ì˜ˆì™¸ ì²˜ë¦¬)
            records = []
            with open(self.log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if line.strip():
                        try:
                            records.append(json.loads(line))
                        except json.JSONDecodeError as e:
                            # íŒŒì‹± ì‹¤íŒ¨í•œ ë¼ì¸ì€ ìŠ¤í‚µ
                            print(f"[ê²½ê³ ] íŒ¨í„´ ì—…ë°ì´íŠ¸ ì¤‘ ë¼ì¸ {line_num} íŒŒì‹± ì‹¤íŒ¨: {e}")
                            continue

            # í•´ë‹¹ pattern_id ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
            updated = False
            for record in records:
                if record.get('pattern_id') == pattern_id:
                    # ê¸°ë³¸ ë§¤ë§¤ ê²°ê³¼
                    result_data = {
                        'trade_executed': trade_executed,
                        'profit_rate': profit_rate,
                        'sell_reason': sell_reason,
                        'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }

                    # ğŸ†• ë§¤ìˆ˜~ë§¤ë„ êµ¬ê°„ ìƒì„¸ ë¶„ì„ ì¶”ê°€
                    if trade_data is not None:
                        post_trade_analysis = self._analyze_post_trade_trajectory(trade_data)
                        result_data['post_trade_analysis'] = post_trade_analysis

                    record['trade_result'] = result_data
                    updated = True
                    break

            if updated:
                # íŒŒì¼ ë‹¤ì‹œ ì“°ê¸° (ì˜ˆì™¸ ì²˜ë¦¬)
                with open(self.log_file, 'w', encoding='utf-8') as f:
                    for record in records:
                        try:
                            json_str = json.dumps(record, ensure_ascii=False)
                            # JSONì´ ìœ íš¨í•œì§€ ê²€ì¦
                            json.loads(json_str)
                            f.write(json_str + '\n')
                        except Exception as e:
                            print(f"[ê²½ê³ ] ë ˆì½”ë“œ ì“°ê¸° ì‹¤íŒ¨ ({record.get('pattern_id', 'unknown')}): {e}")
                            continue
                    f.flush()
        except Exception as e:
            print(f"[ê²½ê³ ] íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({pattern_id}): {e}")

    def _load_existing_pattern_ids(self) -> set:
        """
        ê¸°ì¡´ íŒ¨í„´ íŒŒì¼ì—ì„œ ì´ë¯¸ ì €ì¥ëœ íŒ¨í„´ ID ë¡œë“œ
        ì¤‘ë³µ ë°©ì§€ìš©

        Returns:
            set: ê¸°ì¡´ íŒ¨í„´ ID ì§‘í•©
        """
        existing_ids = set()

        if not self.log_file.exists():
            return existing_ids

        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        record = json.loads(line)
                        pattern_id = record.get('pattern_id')
                        if pattern_id:
                            existing_ids.add(pattern_id)
                    except json.JSONDecodeError:
                        # ì†ìƒëœ ë¼ì¸ì€ ë¬´ì‹œ
                        continue

            print(f"[íŒ¨í„´ë¡œê±°] ê¸°ì¡´ íŒ¨í„´ ID {len(existing_ids)}ê°œ ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"[ê²½ê³ ] ê¸°ì¡´ íŒ¨í„´ ID ë¡œë“œ ì‹¤íŒ¨: {e}")

        return existing_ids

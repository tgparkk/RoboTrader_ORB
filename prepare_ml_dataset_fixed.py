#!/usr/bin/env python3
"""
signal_replay_log í´ë”ì˜ ê³ ì • ì†ìµë¹„ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ML í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜

ì…ë ¥: signal_replay_log/signal_new2_replay_*.txt (ê³ ì • 3.5:2.5 ì†ìµë¹„ ì‹œë®¬)
ì¶œë ¥: ml_dataset_fixed.csv (í•™ìŠµìš© í”¼ì²˜ + ë¼ë²¨)

ì‚¬ìš©ë²•:
    python prepare_ml_dataset_fixed.py
"""

import re
import os
import json
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import List, Dict, Optional


# ì„¤ì •
TEST_RESULTS_DIR = "signal_replay_log"  # ê³ ì • ì†ìµë¹„ ì‹œë®¬ ê²°ê³¼
PATTERN_LOG_DIR = "pattern_data_log"  # ê³ ì • ì†ìµë¹„ íŒ¨í„´ ë¡œê·¸
CACHE_DIR = "cache/minute_data"
OUTPUT_FILE = "ml_dataset_fixed.csv"


def parse_trade_line(line: str) -> Optional[Dict]:
    """
    ê±°ë˜ ê²°ê³¼ ë¼ì¸ íŒŒì‹±
    ì˜ˆ: ğŸŸ¢ 000390(ì‚¼í™”í˜ì¸íŠ¸) 09:33 ë§¤ìˆ˜ â†’ +7.00%
    """
    # ìŠ¹ë¦¬ íŒ¨í„´ (ğŸŸ¢)
    win_match = re.search(r'ğŸŸ¢\s+(\d+)\((.+?)\)\s+(\d{2}:\d{2})\s+ë§¤ìˆ˜\s+â†’\s+\+?([\d.]+)%', line)
    if win_match:
        return {
            'stock_code': win_match.group(1),
            'stock_name': win_match.group(2),
            'buy_time': win_match.group(3),
            'profit_rate': float(win_match.group(4)),
            'result': 'win'
        }

    # ì†ì‹¤ íŒ¨í„´ (ğŸ”´)
    loss_match = re.search(r'ğŸ”´\s+(\d+)\((.+?)\)\s+(\d{2}:\d{2})\s+ë§¤ìˆ˜\s+â†’\s+([+-]?[\d.]+)%', line)
    if loss_match:
        return {
            'stock_code': loss_match.group(1),
            'stock_name': loss_match.group(2),
            'buy_time': loss_match.group(3),
            'profit_rate': float(loss_match.group(4)),
            'result': 'loss'
        }

    return None


def parse_simulation_file(file_path: str) -> List[Dict]:
    """ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ì—ì„œ ëª¨ë“  ê±°ë˜ ê²°ê³¼ ì¶”ì¶œ"""
    date_match = re.search(r'signal_new2_replay_(\d{8})_', file_path)
    if not date_match:
        return []

    trade_date = date_match.group(1)
    trades = []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                trade = parse_trade_line(line)
                if trade:
                    trade['date'] = trade_date
                    trades.append(trade)
    except Exception as e:
        print(f"íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ {file_path}: {e}")
        return []

    return trades


def load_pattern_data(stock_code: str, trade_date: str, signal_time: str) -> Optional[Dict]:
    """
    pattern_data_logì—ì„œ í•´ë‹¹ ê±°ë˜ì˜ íŒ¨í„´ ì •ë³´ ë¡œë“œ

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        trade_date: YYYYMMDD
        signal_time: HH:MM
    """
    pattern_file = os.path.join(PATTERN_LOG_DIR, f"pattern_data_{trade_date}.jsonl")

    if not os.path.exists(pattern_file):
        return None

    try:
        # UTF-8 ì‹¤íŒ¨ ì‹œ CP949ë¡œ ì¬ì‹œë„
        encodings = ['utf-8', 'cp949', 'utf-8-sig']

        for encoding in encodings:
            try:
                with open(pattern_file, 'r', encoding=encoding) as f:
                    for line in f:
                        if line.strip():
                            try:
                                pattern = json.loads(line)
                                if pattern.get('stock_code') == stock_code:
                                    # ì‹ í˜¸ ì‹œê°„ ë§¤ì¹­ (YYYY-MM-DD HH:MM:SS í˜•ì‹ì—ì„œ HH:MMë§Œ ì¶”ì¶œ)
                                    pattern_signal_time = pattern.get('signal_time', '')
                                    # "2025-12-22 09:33:00" â†’ "09:33"ì™€ ë§¤ì¹­
                                    if len(pattern_signal_time) >= 16:
                                        time_part = pattern_signal_time[11:16]  # "09:33"
                                        if time_part == signal_time:
                                            return pattern
                            except json.JSONDecodeError:
                                continue
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
            except UnicodeDecodeError:
                continue  # ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„

    except Exception as e:
        print(f"íŒ¨í„´ ë¡œê·¸ ë¡œë“œ ì˜¤ë¥˜ {pattern_file}: {e}")

    return None


def extract_features_from_pattern(pattern_stages: Dict, signal_info: Dict) -> Dict:
    """íŒ¨í„´ 4ë‹¨ê³„ ì •ë³´ì—ì„œ ML í”¼ì²˜ ì¶”ì¶œ + ë™ì  ì†ìµë¹„ ëª©í‘œê°’ ì¶”ê°€"""
    from config.dynamic_profit_loss_config import DynamicProfitLossConfig

    features = {}

    def safe_float(value, default=0.0):
        """ì•ˆì „í•œ float ë³€í™˜"""
        if value is None:
            return default
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            return float(value.replace('%', '').replace(',', ''))
        return default

    def calculate_avg_body_pct(candles: list) -> float:
        """ìº”ë“¤ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ëª¸í†µ í¬ê¸° ê³„ì‚°"""
        if not candles:
            return 0.0
        body_pcts = []
        for c in candles:
            open_p = c.get('open', 0)
            close_p = c.get('close', 0)
            if open_p > 0:
                body_pct = abs((close_p - open_p) / open_p * 100)
                body_pcts.append(body_pct)
        return sum(body_pcts) / len(body_pcts) if body_pcts else 0.0

    # 1ë‹¨ê³„: ìƒìŠ¹êµ¬ê°„
    uptrend = pattern_stages.get('1_uptrend', {})
    uptrend_candles_list = uptrend.get('candles', [])
    features['uptrend_candles'] = uptrend.get('candle_count', len(uptrend_candles_list))
    features['uptrend_gain'] = safe_float(uptrend.get('price_gain', 0))
    features['uptrend_max_volume'] = safe_float(uptrend.get('max_volume', 0))

    # uptrend_avg_body: í‰ê·  ëª¸í†µ í¬ê¸° (ê¸°ì¡´ ëª¨ë¸ íŠ¹ì„±)
    features['uptrend_avg_body'] = calculate_avg_body_pct(uptrend_candles_list)

    # uptrend_total_volume: ì´ ê±°ë˜ëŸ‰ (ê¸°ì¡´ ëª¨ë¸ íŠ¹ì„±)
    total_volume = uptrend.get('total_volume')
    if total_volume is None:
        total_volume = sum(c.get('volume', 0) for c in uptrend_candles_list)
    features['uptrend_total_volume'] = safe_float(total_volume)

    # 2ë‹¨ê³„: í•˜ë½êµ¬ê°„
    decline = pattern_stages.get('2_decline', {})
    features['decline_candles'] = decline.get('candle_count', 0)
    features['decline_pct'] = safe_float(decline.get('decline_pct', 0))
    features['decline_avg_volume'] = safe_float(decline.get('avg_volume', 0))

    # 3ë‹¨ê³„: ì§€ì§€êµ¬ê°„
    support = pattern_stages.get('3_support', {})
    features['support_candles'] = support.get('candle_count', 0)
    features['support_volatility'] = safe_float(support.get('price_volatility', 0))
    features['support_avg_volume_ratio'] = safe_float(support.get('avg_volume_ratio', 1.0))
    features['support_avg_volume'] = safe_float(support.get('avg_volume', 0))

    # 4ë‹¨ê³„: ëŒíŒŒì–‘ë´‰
    breakout = pattern_stages.get('4_breakout', {})
    breakout_candle = breakout.get('candle', {})
    features['breakout_volume'] = safe_float(breakout_candle.get('volume', 0))

    # breakout_body: ëª¸í†µ í¬ê¸° í¼ì„¼íŠ¸ (ê¸°ì¡´ ëª¨ë¸ íŠ¹ì„±)
    open_p = breakout_candle.get('open', 0)
    close_p = breakout_candle.get('close', 0)
    if open_p > 0:
        features['breakout_body'] = abs((close_p - open_p) / open_p * 100)
    else:
        features['breakout_body'] = 0.0

    # breakout_range: ë²”ìœ„ í¬ê¸° (ê¸°ì¡´ ëª¨ë¸ íŠ¹ì„±)
    high_p = breakout_candle.get('high', 0)
    low_p = breakout_candle.get('low', 0)
    if low_p > 0:
        features['breakout_range'] = (high_p - low_p) / low_p * 100
    else:
        features['breakout_range'] = 0.0

    # === ë¹„ìœ¨ íŠ¹ì„± ê³„ì‚° (ê¸°ì¡´ ëª¨ë¸ê³¼ ë™ì¼í•œ 5ê°œ) ===
    volume_ratio_decline_to_uptrend = (
        features['decline_avg_volume'] / features['uptrend_max_volume']
        if features['uptrend_max_volume'] > 0 else 0
    )
    volume_ratio_support_to_uptrend = (
        features['support_avg_volume'] / features['uptrend_max_volume']
        if features['uptrend_max_volume'] > 0 else 0
    )
    volume_ratio_breakout_to_uptrend = (
        features['breakout_volume'] / features['uptrend_max_volume']
        if features['uptrend_max_volume'] > 0 else 0
    )
    price_gain_to_decline_ratio = (
        features['uptrend_gain'] / features['decline_pct']
        if features['decline_pct'] > 0 else 0
    )
    candle_ratio_support_to_decline = (
        features['support_candles'] / features['decline_candles']
        if features['decline_candles'] > 0 else 0
    )

    features['volume_ratio_decline_to_uptrend'] = volume_ratio_decline_to_uptrend
    features['volume_ratio_support_to_uptrend'] = volume_ratio_support_to_uptrend
    features['volume_ratio_breakout_to_uptrend'] = volume_ratio_breakout_to_uptrend
    features['price_gain_to_decline_ratio'] = price_gain_to_decline_ratio
    features['candle_ratio_support_to_decline'] = candle_ratio_support_to_decline

    # ì‹ í˜¸ ì •ë³´
    signal_type = signal_info.get('signal_type', 'STRONG_BUY')
    features['signal_type'] = signal_type  # LabelEncodingì€ í•™ìŠµ ì‹œ ì²˜ë¦¬
    features['confidence'] = signal_info.get('confidence', 0)

    # ê³ ì • ì†ìµë¹„ ëª¨ë“œì—ì„œëŠ” target_stop_loss, target_take_profit ë¶ˆí•„ìš”
    # (í•­ìƒ ê³ ì •ê°’ 3.5:2.5 ì‚¬ìš©)

    return features


def process_all_simulations():
    """ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ ì²˜ë¦¬"""
    all_data = []

    # ë™ì  ì†ìµë¹„ ì‹œë®¬ ê²°ê³¼ë§Œ ì‚¬ìš©
    sim_files = sorted(Path(TEST_RESULTS_DIR).glob("signal_new2_replay_*.txt"))
    print(f"{TEST_RESULTS_DIR}: {len(sim_files)}ê°œ íŒŒì¼")
    print(f"\nì´ {len(sim_files)}ê°œ ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼ ë°œê²¬")

    for sim_file in sim_files:
        print(f"\nì²˜ë¦¬ ì¤‘: {sim_file.name}")

        # ê±°ë˜ ê²°ê³¼ íŒŒì‹±
        trades = parse_simulation_file(str(sim_file))
        print(f"  - {len(trades)}ê±´ ê±°ë˜ ë°œê²¬")

        # ê° ê±°ë˜ì— ëŒ€í•´ íŒ¨í„´ ì •ë³´ ë§¤ì¹­
        matched = 0
        for trade in trades:
            # íŒ¨í„´ ë°ì´í„° ë¡œë“œ
            pattern = load_pattern_data(
                trade['stock_code'],
                trade['date'],
                trade['buy_time']
            )

            if pattern is None:
                continue

            # íŒ¨í„´ íŠ¹ì§• ì¶”ì¶œ
            pattern_stages = pattern.get('pattern_stages', {})
            signal_info = pattern.get('signal_info', {})

            features = extract_features_from_pattern(pattern_stages, signal_info)

            # ë¼ë²¨ ì¶”ê°€
            features['label'] = 1 if trade['result'] == 'win' else 0
            features['profit_rate'] = trade['profit_rate']
            features['stock_code'] = trade['stock_code']
            features['stock_name'] = trade['stock_name']
            features['date'] = trade['date']
            features['buy_time'] = trade['buy_time']

            # ì‹œê°„ íŠ¹ì§•
            hour, minute = map(int, trade['buy_time'].split(':'))
            features['hour'] = hour
            features['minute'] = minute
            features['time_in_minutes'] = hour * 60 + minute
            features['is_morning'] = 1 if hour < 12 else 0

            all_data.append(features)
            matched += 1

        print(f"  - {matched}ê±´ íŒ¨í„´ ë§¤ì¹­ ì„±ê³µ")

    return pd.DataFrame(all_data)


def main():
    print("=" * 80)
    print("test_results --> ML ë°ì´í„°ì…‹ ë³€í™˜ ì‹œì‘")
    print("=" * 80)

    # ë°ì´í„° ì²˜ë¦¬
    df = process_all_simulations()

    if len(df) == 0:
        print("\n[ê²½ê³ ] ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    # ë°ì´í„° ì €ì¥
    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
    print(f"\n[ì™„ë£Œ] ML ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {OUTPUT_FILE}")
    print(f"   ì´ {len(df)}ê±´ (ìŠ¹ë¦¬ {df['label'].sum()}ê±´, íŒ¨ë°° {len(df) - df['label'].sum()}ê±´)")

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 80)
    print("[í†µê³„] ë°ì´í„°ì…‹ í†µê³„")
    print("=" * 80)

    print(f"\nì´ ê±°ë˜ ê±´ìˆ˜: {len(df)}")
    print(f"  - ìŠ¹ë¦¬: {df['label'].sum()}ê±´ ({df['label'].mean()*100:.1f}%)")
    print(f"  - íŒ¨ë°°: {len(df) - df['label'].sum()}ê±´ ({(1-df['label'].mean())*100:.1f}%)")

    print(f"\ní‰ê·  ìˆ˜ìµë¥ : {df['profit_rate'].mean():.2f}%")
    print(f"  - ìŠ¹ë¦¬ ì‹œ: {df[df['label']==1]['profit_rate'].mean():.2f}%")
    print(f"  - íŒ¨ë°° ì‹œ: {df[df['label']==0]['profit_rate'].mean():.2f}%")

    # ì‹œê°„ëŒ€ë³„ í†µê³„
    print("\n=== ì‹œê°„ëŒ€ë³„ ìŠ¹ë¥  ===")
    time_stats = df.groupby('hour').agg({
        'label': ['count', 'mean'],
        'profit_rate': 'mean'
    }).round(2)
    time_stats.columns = ['count', 'win_rate', 'avg_profit']
    time_stats['win_rate'] = (time_stats['win_rate'] * 100).round(1)
    print(time_stats.to_string())

    print("\n" + "=" * 80)
    print(f"[ì™„ë£Œ] ML ëª¨ë¸ í•™ìŠµì— {OUTPUT_FILE}ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    print("=" * 80)


if __name__ == "__main__":
    main()

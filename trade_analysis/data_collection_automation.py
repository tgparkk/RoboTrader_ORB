"""
ë°ì´í„° ìˆ˜ì§‘ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
ë” ë§ì€ ê¸°ê°„ê³¼ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¶„ì„ í’ˆì§ˆ í–¥ìƒ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import json
import logging
from typing import List, Dict, Optional
import time

from api.kis_market_api import get_inquire_daily_itemchartprice
from utils.logger import setup_logger
from utils.korean_time import now_kst

class DataCollectionAutomation:
    """ë°ì´í„° ìˆ˜ì§‘ ìë™í™”"""
    
    def __init__(self, logger=None):
        self.logger = logger or setup_logger(__name__)
        self.cache_dir = Path("cache/daily_data")
        self.cache_dir.mkdir(exist_ok=True)
        
    def collect_extended_data(self, start_date: str, end_date: str, stock_codes: List[str]):
        """í™•ì¥ëœ ê¸°ê°„ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self.logger.info(f" í™•ì¥ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
            
            # 1. ë‚ ì§œ ë²”ìœ„ ìƒì„±
            date_range = self._generate_date_range(start_date, end_date)
            self.logger.info(f"ğŸ“… ìˆ˜ì§‘í•  ë‚ ì§œ: {len(date_range)}ê°œ")
            
            # 2. ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜ì§‘
            collected_data = {}
            for i, stock_code in enumerate(stock_codes, 1):
                self.logger.info(f" [{i}/{len(stock_codes)}] {stock_code} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                try:
                    # ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
                    daily_data = self._collect_daily_data(stock_code, date_range)
                    if daily_data is not None and not daily_data.empty:
                        collected_data[stock_code] = daily_data
                        self.logger.info(f"âœ… {stock_code}: {len(daily_data)}ê°œ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                    else:
                        self.logger.warning(f"âš ï¸ {stock_code}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    
                    # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
                    time.sleep(0.1)
                    
                except Exception as e:
                    self.logger.error(f"âŒ {stock_code} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # 3. ë°ì´í„° ì €ì¥
            self._save_collected_data(collected_data)
            
            # 4. ìˆ˜ì§‘ í†µê³„ ìƒì„±
            stats = self._generate_collection_stats(collected_data)
            self.logger.info(f" ìˆ˜ì§‘ ì™„ë£Œ: {stats}")
            
            return collected_data
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _generate_date_range(self, start_date: str, end_date: str) -> List[str]:
        """ë‚ ì§œ ë²”ìœ„ ìƒì„±"""
        start_dt = datetime.strptime(start_date, "%Y%m%d")
        end_dt = datetime.strptime(end_date, "%Y%m%d")
        
        date_range = []
        current_dt = start_dt
        
        while current_dt <= end_dt:
            # ì£¼ë§ ì œì™¸
            if current_dt.weekday() < 5:
                date_range.append(current_dt.strftime("%Y%m%d"))
            current_dt += timedelta(days=1)
        
        return date_range
    
    def _collect_daily_data(self, stock_code: str, date_range: List[str]) -> Optional[pd.DataFrame]:
        """ì¢…ëª©ë³„ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            all_data = []
            
            for date in date_range:
                try:
                    # API í˜¸ì¶œ
                    data = get_inquire_daily_itemchartprice(
                        stock_code=stock_code,
                        period_code="D",
                        adj_price="1",
                        start_date=date,
                        end_date=date
                    )
                    
                    if data and not data.empty:
                        all_data.append(data)
                    
                    # API í˜¸ì¶œ ì œí•œ
                    time.sleep(0.05)
                    
                except Exception as e:
                    self.logger.debug(f"ë‚ ì§œ {date} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            if not all_data:
                return None
            
            # ë°ì´í„° ê²°í•©
            combined_data = pd.concat(all_data, ignore_index=True)
            combined_data = combined_data.drop_duplicates().sort_values('stck_bsop_date')
            
            return combined_data
            
        except Exception as e:
            self.logger.error(f"ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ {stock_code}: {e}")
            return None
    
    def _save_collected_data(self, collected_data: Dict[str, pd.DataFrame]):
        """ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥"""
        try:
            for stock_code, data in collected_data.items():
                file_path = self.cache_dir / f"{stock_code}_daily.pkl"
                with open(file_path, 'wb') as f:
                    pickle.dump(data, f)
            
            self.logger.info(f"ğŸ’¾ {len(collected_data)}ê°œ ì¢…ëª© ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _generate_collection_stats(self, collected_data: Dict[str, pd.DataFrame]) -> Dict:
        """ìˆ˜ì§‘ í†µê³„ ìƒì„±"""
        stats = {
            'total_stocks': len(collected_data),
            'total_records': sum(len(data) for data in collected_data.values()),
            'avg_records_per_stock': 0,
            'date_range': {},
            'success_rate': 0
        }
        
        if collected_data:
            stats['avg_records_per_stock'] = stats['total_records'] / len(collected_data)
            
            # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
            all_dates = set()
            for data in collected_data.values():
                if 'stck_bsop_date' in data.columns:
                    all_dates.update(data['stck_bsop_date'].astype(str))
            
            if all_dates:
                stats['date_range'] = {
                    'start': min(all_dates),
                    'end': max(all_dates),
                    'total_days': len(all_dates)
                }
        
        return stats
    
    def collect_market_data(self, start_date: str, end_date: str):
        """ì‹œì¥ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self.logger.info(" ì‹œì¥ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
            # 1. ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
            stock_codes = self._load_major_stocks()
            self.logger.info(f" ìˆ˜ì§‘ ëŒ€ìƒ ì¢…ëª©: {len(stock_codes)}ê°œ")
            
            # 2. ë°ì´í„° ìˆ˜ì§‘
            collected_data = self.collect_extended_data(start_date, end_date, stock_codes)
            
            # 3. ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
            index_data = self._collect_index_data(start_date, end_date)
            
            # 4. ê²°ê³¼ ì €ì¥
            self._save_market_data(collected_data, index_data)
            
            return collected_data, index_data
            
        except Exception as e:
            self.logger.error(f"ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}, {}
    
    def _load_major_stocks(self) -> List[str]:
        """ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
        try:
            # ê¸°ì¡´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
            stock_list_file = Path("stock_list.json")
            if stock_list_file.exists():
                with open(stock_list_file, 'r', encoding='utf-8') as f:
                    stock_data = json.load(f)
                    return [stock['code'] for stock in stock_data if 'code' in stock]
            
            # ê¸°ë³¸ ì¢…ëª© ë¦¬ìŠ¤íŠ¸
            return [
                "005930", "000660", "035420", "207940", "006400",  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ë„¤ì´ë²„, ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤, ì‚¼ì„±SDI
                "051910", "068270", "323410", "000270", "035720",  # LGí™”í•™, ì…€íŠ¸ë¦¬ì˜¨, ì¹´ì¹´ì˜¤ë±…í¬, ê¸°ì•„, ì¹´ì¹´ì˜¤
                "066570", "003550", "017670", "096770", "018260",  # LGì „ì, LG, SKí…”ë ˆì½¤, SKì´ë…¸ë² ì´ì…˜, ì‚¼ì„±ë¬¼ì‚°
                "034730", "003490", "015760", "000720", "012330",  # SK, ëŒ€ìš°ê±´ì„¤, í•œêµ­ì „ë ¥, í˜„ëŒ€ê±´ì„¤, í˜„ëŒ€ëª¨ë¹„ìŠ¤
                "066970", "000810", "003410", "161890", "105560"   # ì—˜ì•¤ì—í”„, ì‚¼ì„±í™”ì¬, ì‹ ì„¸ê³„, í•œí™”ì†”ë£¨ì…˜, KBê¸ˆìœµ
            ]
            
        except Exception as e:
            self.logger.error(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _collect_index_data(self, start_date: str, end_date: str) -> Dict[str, pd.DataFrame]:
        """ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            index_codes = {
                "KOSPI": "0001",      # KOSPI
                "KOSDAQ": "1001",     # KOSDAQ
                "KOSPI200": "0002"    # KOSPI200
            }
            
            index_data = {}
            for name, code in index_codes.items():
                try:
                    data = get_inquire_daily_itemchartprice(
                        stock_code=code,
                        period_code="D",
                        adj_price="1",
                        start_date=start_date,
                        end_date=end_date
                    )
                    
                    if data is not None and not data.empty:
                        index_data[name] = data
                        self.logger.info(f"âœ… {name} ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(data)}ê°œ")
                    
                    time.sleep(0.1)
                    
                except Exception as e:
                    self.logger.error(f"âŒ {name} ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            return index_data
            
        except Exception as e:
            self.logger.error(f"ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _save_market_data(self, stock_data: Dict[str, pd.DataFrame], index_data: Dict[str, pd.DataFrame]):
        """ì‹œì¥ ë°ì´í„° ì €ì¥"""
        try:
            # ì¢…ëª© ë°ì´í„° ì €ì¥
            for stock_code, data in stock_data.items():
                file_path = self.cache_dir / f"{stock_code}_daily.pkl"
                with open(file_path, 'wb') as f:
                    pickle.dump(data, f)
            
            # ì§€ìˆ˜ ë°ì´í„° ì €ì¥
            index_dir = Path("cache/index_data")
            index_dir.mkdir(exist_ok=True)
            
            for index_name, data in index_data.items():
                file_path = index_dir / f"{index_name}_daily.pkl"
                with open(file_path, 'wb') as f:
                    pickle.dump(data, f)
            
            self.logger.info(f" ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(stock_data)}ê°œ ì¢…ëª©, {len(index_data)}ê°œ ì§€ìˆ˜")
            
        except Exception as e:
            self.logger.error(f"ì‹œì¥ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger = setup_logger(__name__)
    
    # ë°ì´í„° ìˆ˜ì§‘ ìë™í™” ì‹¤í–‰
    collector = DataCollectionAutomation(logger)
    
    # 1. í™•ì¥ëœ ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘ (3ê°œì›”)
    start_date = "20240601"  # 6ì›” 1ì¼
    end_date = "20250917"    # 9ì›” 17ì¼
    
    logger.info(f" í™•ì¥ëœ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
    
    # 2. ì‹œì¥ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
    stock_data, index_data = collector.collect_market_data(start_date, end_date)
    
    # 3. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    logger.info(" ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
    logger.info(f"  - ì¢…ëª© ë°ì´í„°: {len(stock_data)}ê°œ")
    logger.info(f"  - ì§€ìˆ˜ ë°ì´í„°: {len(index_data)}ê°œ")
    
    if stock_data:
        total_records = sum(len(data) for data in stock_data.values())
        logger.info(f"  - ì´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê°œ")
        logger.info(f"  - í‰ê·  ë ˆì½”ë“œ/ì¢…ëª©: {total_records // len(stock_data):,}ê°œ")


if __name__ == "__main__":
    main()

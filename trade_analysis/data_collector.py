#!/usr/bin/env python3
"""
ë¶„ì„ìš© ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
ë‚ ì§œ ë²”ìœ„ë³„ í›„ë³´ ì¢…ëª© ì¡°íšŒ ë° ì¼ë´‰/ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘
"""
import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
import pickle
import sqlite3

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from db.database_manager import DatabaseManager
from api.kis_chart_api import get_historical_minute_data, get_inquire_time_dailychartprice
from api.kis_auth import KisAuth
from utils.logger import setup_logger
from utils.korean_time import now_kst

logger = setup_logger(__name__)


class AnalysisDataCollector:
    """ë¶„ì„ìš© ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, db_path: str = None):
        """
        Args:
            db_path: ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ (ê¸°ë³¸ê°’: C:\GIT\RoboTrader\data\robotrader.db)
        """
        self.logger = setup_logger(__name__)

        # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì •
        if db_path is None:
            db_path = project_root / "data" / "robotrader.db"
        self.db_path = str(db_path)

        # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.daily_cache_dir = project_root / "cache" / "daily_data"
        self.minute_cache_dir = project_root / "cache" / "minute_data"

        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.db_manager = DatabaseManager(self.db_path)

        # KIS API ì¸ì¦ ì´ˆê¸°í™”
        self.kis_auth = KisAuth()
        self._api_initialized = False

        self.logger.info(f"ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"  DB ê²½ë¡œ: {self.db_path}")
        self.logger.info(f"  ì¼ë´‰ ìºì‹œ: {self.daily_cache_dir}")
        self.logger.info(f"  ë¶„ë´‰ ìºì‹œ: {self.minute_cache_dir}")

    def _ensure_api_initialized(self) -> bool:
        """API ì¸ì¦ì´ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ì´ˆê¸°í™”"""
        if self._api_initialized and self.kis_auth.is_authenticated():
            return True

        self.logger.info("ğŸ”‘ KIS API ì¸ì¦ ì´ˆê¸°í™” ì¤‘...")
        if self.kis_auth.initialize():
            self._api_initialized = True
            self.logger.info("âœ… KIS API ì¸ì¦ ì™„ë£Œ")
            return True
        else:
            self.logger.error("âŒ KIS API ì¸ì¦ ì‹¤íŒ¨")
            return False

    def check_minute_data_sufficiency(self, stock_code: str, date_str: str, required_count: int = 15) -> bool:
        """
        ë¶„ë´‰ ë°ì´í„° ì¶©ë¶„ì„± ê²€ì‚¬

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)
            required_count: í•„ìš”í•œ ìµœì†Œ ë°ì´í„° ê°œìˆ˜

        Returns:
            bool: ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
        """
        try:
            minute_data = self.get_minute_data_from_cache(stock_code, date_str)
            if minute_data is None or len(minute_data) < required_count:
                self.logger.warning(f"âŒ {stock_code} {date_str} ë¶„ë´‰ ë°ì´í„° ë¶€ì¡±: {len(minute_data) if minute_data is not None else 0}ê°œ (ìµœì†Œ {required_count}ê°œ í•„ìš”)")
                return False

            # í˜„ì¬ ì‹œê°„ê³¼ ë¹„êµí•˜ì—¬ ë°ì´í„°ê°€ ìµœì‹ ì¸ì§€ í™•ì¸
            current_time = now_kst()
            current_date = current_time.strftime('%Y%m%d')

            if date_str == current_date:
                # ì˜¤ëŠ˜ ë‚ ì§œì¸ ê²½ìš° í˜„ì¬ ì‹œê°„ê¹Œì§€ì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                current_hour = current_time.hour
                current_minute = current_time.minute

                # ì¥ ì‹œì‘ ì‹œê°„ (09:00) ì´í›„ì¸ ê²½ìš°
                if current_hour >= 9:
                    # í˜„ì¬ ì‹œê°„ê¹Œì§€ ì˜ˆìƒë˜ëŠ” ë¶„ë´‰ ê°œìˆ˜ ê³„ì‚°
                    if current_hour < 15 or (current_hour == 15 and current_minute <= 30):
                        # ì¥ì¤‘ì¸ ê²½ìš°: 09:00ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë¶„ë´‰ ê°œìˆ˜
                        expected_count = (current_hour - 9) * 60 + current_minute
                        if len(minute_data) < expected_count * 0.8:  # 80% ì´ìƒ ìˆì–´ì•¼ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨
                            self.logger.warning(f"âŒ {stock_code} {date_str} ë¶„ë´‰ ë°ì´í„° ë¶€ì¡±: {len(minute_data)}ê°œ (ì˜ˆìƒ {expected_count}ê°œ)")
                            return False
                    else:
                        # ì¥ ë§ˆê° í›„ì¸ ê²½ìš°: 09:00~15:30 (390ë¶„)
                        if len(minute_data) < 350:  # 350ê°œ ì´ìƒ ìˆì–´ì•¼ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨
                            self.logger.warning(f"âŒ {stock_code} {date_str} ë¶„ë´‰ ë°ì´í„° ë¶€ì¡±: {len(minute_data)}ê°œ (ì¥ ë§ˆê° í›„ ìµœì†Œ 350ê°œ í•„ìš”)")
                            return False

            self.logger.debug(f"âœ… {stock_code} {date_str} ë¶„ë´‰ ë°ì´í„° ì¶©ë¶„: {len(minute_data)}ê°œ")
            return True

        except Exception as e:
            self.logger.error(f"ë¶„ë´‰ ë°ì´í„° ì¶©ë¶„ì„± ê²€ì‚¬ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return False

    def collect_full_data_for_stock(self, stock_code: str, date_str: str, use_api: bool = True) -> bool:
        """
        íŠ¹ì • ì¢…ëª©ì˜ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ì¼ë´‰ + ë¶„ë´‰)

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)
            use_api: API ì‚¬ìš© ì—¬ë¶€

        Returns:
            bool: ìˆ˜ì§‘ ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.logger.info(f"ğŸ”„ {stock_code} ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {date_str}")

            # API ì¸ì¦ í™•ì¸
            if use_api and not self._ensure_api_initialized():
                self.logger.warning(f"API ì¸ì¦ ì‹¤íŒ¨ë¡œ {stock_code} ë°ì´í„° ìˆ˜ì§‘ ë¶ˆê°€")
                use_api = False

            success_count = 0
            total_count = 2  # ì¼ë´‰ + ë¶„ë´‰

            # 1. ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            daily_data = self.get_daily_data(stock_code, date_str, use_api)
            if daily_data is not None and not daily_data.empty:
                success_count += 1
                self.logger.info(f"âœ… {stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(daily_data)}ê±´")
            else:
                self.logger.warning(f"âŒ {stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

            # 2. ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘
            minute_data = self.get_minute_data(stock_code, date_str, use_api)
            if minute_data is not None and not minute_data.empty:
                success_count += 1
                self.logger.info(f"âœ… {stock_code} ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(minute_data)}ê±´")
            else:
                self.logger.warning(f"âŒ {stock_code} ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

            success_rate = (success_count / total_count) * 100
            self.logger.info(f"ğŸ“Š {stock_code} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{total_count} ({success_rate:.1f}%)")

            return success_count == total_count

        except Exception as e:
            self.logger.error(f"ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return False

    def ensure_sufficient_data(self, stock_code: str, date_str: str, required_minute_count: int = 15, use_api: bool = True) -> bool:
        """
        ë°ì´í„° ì¶©ë¶„ì„± í™•ì¸ ë° í•„ìš”ì‹œ ì „ì²´ ìˆ˜ì§‘

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)
            required_minute_count: í•„ìš”í•œ ìµœì†Œ ë¶„ë´‰ ê°œìˆ˜
            use_api: API ì‚¬ìš© ì—¬ë¶€

        Returns:
            bool: ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
        """
        try:
            # 1. í˜„ì¬ ë°ì´í„° ì¶©ë¶„ì„± ê²€ì‚¬
            if self.check_minute_data_sufficiency(stock_code, date_str, required_minute_count):
                return True

            # 2. ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ì „ì²´ ìˆ˜ì§‘
            self.logger.info(f"ğŸ”„ {stock_code} ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì „ì²´ ìˆ˜ì§‘ ì‹œì‘...")
            return self.collect_full_data_for_stock(stock_code, date_str, use_api)

        except Exception as e:
            self.logger.error(f"ë°ì´í„° ì¶©ë¶„ì„± í™•ì¸ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return False

    def get_candidate_stocks_by_date_range(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        ë‚ ì§œ ë²”ìœ„ë³„ í›„ë³´ ì¢…ëª© ì¡°íšŒ

        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)

        Returns:
            pd.DataFrame: í›„ë³´ ì¢…ëª© ë°ì´í„°
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = '''
                    SELECT
                        id,
                        stock_code,
                        stock_name,
                        selection_date,
                        score,
                        reasons,
                        status
                    FROM candidate_stocks
                    WHERE DATE(selection_date) >= ?
                    AND DATE(selection_date) <= ?
                    ORDER BY selection_date DESC, score DESC
                '''

                df = pd.read_sql_query(query, conn, params=(start_date, end_date))
                df['selection_date'] = pd.to_datetime(df['selection_date'])

                self.logger.info(f"í›„ë³´ ì¢…ëª© ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ({start_date} ~ {end_date})")
                return df

        except Exception as e:
            self.logger.error(f"í›„ë³´ ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def get_daily_data_from_cache(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """
        ìºì‹œì—ì„œ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ (ìƒˆë¡œìš´ êµ¬ì¡°: ì¢…ëª©ë³„ í†µí•© íŒŒì¼)

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)

        Returns:
            pd.DataFrame: ì¼ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            cache_file = self.daily_cache_dir / f"{stock_code}_daily.pkl"

            if not cache_file.exists():
                return None

            with open(cache_file, 'rb') as f:
                data = pickle.load(f)

            if isinstance(data, pd.DataFrame) and not data.empty:
                # ë‚ ì§œ í•„í„°ë§
                if 'date' in data.columns:
                    filtered_data = data[data['date'] == date_str]
                    if not filtered_data.empty:
                        self.logger.debug(f"ì¼ë´‰ ìºì‹œì—ì„œ ë¡œë“œ: {stock_code} {date_str} ({len(filtered_data)}ê±´)")
                        return filtered_data
                elif 'datetime' in data.columns:
                    # datetime ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°
                    data['date'] = data['datetime'].dt.strftime('%Y%m%d')
                    filtered_data = data[data['date'] == date_str]
                    if not filtered_data.empty:
                        self.logger.debug(f"ì¼ë´‰ ìºì‹œì—ì„œ ë¡œë“œ: {stock_code} {date_str} ({len(filtered_data)}ê±´)")
                        return filtered_data

                # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì „ì²´ ë°ì´í„° ë°˜í™˜ (í•˜ë£¨ì¹˜ ë°ì´í„°ë¼ê³  ê°€ì •)
                self.logger.debug(f"ì¼ë´‰ ìºì‹œì—ì„œ ë¡œë“œ: {stock_code} {date_str} ({len(data)}ê±´)")
                return data

            return None

        except Exception as e:
            self.logger.error(f"ì¼ë´‰ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return None

    def get_minute_data_from_cache(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """
        ìºì‹œì—ì„œ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)

        Returns:
            pd.DataFrame: ë¶„ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            cache_file = self.minute_cache_dir / f"{stock_code}_{date_str}.pkl"

            if not cache_file.exists():
                return None

            with open(cache_file, 'rb') as f:
                data = pickle.load(f)

            if isinstance(data, pd.DataFrame) and not data.empty:
                self.logger.debug(f"ë¶„ë´‰ ìºì‹œì—ì„œ ë¡œë“œ: {stock_code} {date_str} ({len(data)}ê±´)")
                return data

            return None

        except Exception as e:
            self.logger.error(f"ë¶„ë´‰ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return None

    def get_daily_data_from_api(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """
        APIì—ì„œ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)

        Returns:
            pd.DataFrame: ì¼ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            # API ì¸ì¦ í™•ì¸
            if not self._ensure_api_initialized():
                self.logger.warning(f"API ì¸ì¦ ì‹¤íŒ¨ë¡œ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ ë¶ˆê°€: {stock_code} {date_str}")
                return None

            # ì¼ë´‰ ë°ì´í„°ëŠ” ë¶„ë´‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¡°íšŒ (í•˜ë£¨ ì „ì²´ ë°ì´í„°)
            result = get_inquire_time_dailychartprice(
                div_code="J",  # KRXë§Œ ì‚¬ìš©
                stock_code=stock_code,
                input_date=date_str,
                input_hour="160000",  # ì¥ ë§ˆê° ì‹œê°„
                past_data_yn="Y"
            )

            if result is None:
                return None

            summary_df, chart_df = result

            if chart_df.empty:
                return None

            # ì¼ë´‰ ë°ì´í„°ë¡œ ë³€í™˜ (í•˜ë£¨ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìº”ë“¤ë¡œ)
            if 'datetime' in chart_df.columns:
                # ì‹œê°„ë³„ ë°ì´í„°ë¥¼ ì¼ë´‰ìœ¼ë¡œ ì§‘ê³„
                daily_data = pd.DataFrame({
                    'date': [date_str],
                    'open': [chart_df['open'].iloc[0] if 'open' in chart_df.columns else 0],
                    'high': [chart_df['high'].max() if 'high' in chart_df.columns else 0],
                    'low': [chart_df['low'].min() if 'low' in chart_df.columns else 0],
                    'close': [chart_df['close'].iloc[-1] if 'close' in chart_df.columns else 0],
                    'volume': [chart_df['volume'].sum() if 'volume' in chart_df.columns else 0]
                })

                self.logger.info(f"APIì—ì„œ ì¼ë´‰ ë°ì´í„° ì¡°íšŒ: {stock_code} {date_str}")
                return daily_data

            return None

        except Exception as e:
            self.logger.error(f"API ì¼ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return None

    def get_minute_data_from_api(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """
        APIì—ì„œ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)

        Returns:
            pd.DataFrame: ë¶„ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            # API ì¸ì¦ í™•ì¸
            if not self._ensure_api_initialized():
                self.logger.warning(f"API ì¸ì¦ ì‹¤íŒ¨ë¡œ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ë¶ˆê°€: {stock_code} {date_str}")
                return None

            result = get_historical_minute_data(
                stock_code=stock_code,
                target_date=date_str,
                end_hour="160000",
                past_data_yn="Y"
            )

            if result is not None and not result.empty:
                self.logger.info(f"APIì—ì„œ ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ: {stock_code} {date_str} ({len(result)}ê±´)")
                return result

            return None

        except Exception as e:
            self.logger.error(f"API ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")
            return None

    def get_daily_data(self, stock_code: str, date_str: str, use_api: bool = True) -> Optional[pd.DataFrame]:
        """
        ì¼ë´‰ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ API)

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)
            use_api: API ì‚¬ìš© ì—¬ë¶€

        Returns:
            pd.DataFrame: ì¼ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ìºì‹œì—ì„œ ì¡°íšŒ
        daily_data = self.get_daily_data_from_cache(stock_code, date_str)

        if daily_data is not None:
            return daily_data

        # 2. APIì—ì„œ ì¡°íšŒ (use_apiê°€ Trueì¸ ê²½ìš°)
        if use_api:
            daily_data = self.get_daily_data_from_api(stock_code, date_str)
            if daily_data is not None:
                # ìºì‹œì— ì €ì¥
                self._save_daily_data_to_cache(stock_code, date_str, daily_data)
                return daily_data

        self.logger.warning(f"ì¼ë´‰ ë°ì´í„° ì—†ìŒ: {stock_code} {date_str}")
        return None

    def get_minute_data(self, stock_code: str, date_str: str, use_api: bool = True) -> Optional[pd.DataFrame]:
        """
        ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ìš°ì„ , ì—†ìœ¼ë©´ API)

        Args:
            stock_code: ì¢…ëª©ì½”ë“œ
            date_str: ë‚ ì§œ (YYYYMMDD)
            use_api: API ì‚¬ìš© ì—¬ë¶€

        Returns:
            pd.DataFrame: ë¶„ë´‰ ë°ì´í„° ë˜ëŠ” None
        """
        # 1. ìºì‹œì—ì„œ ì¡°íšŒ
        minute_data = self.get_minute_data_from_cache(stock_code, date_str)

        if minute_data is not None:
            return minute_data

        # 2. APIì—ì„œ ì¡°íšŒ (use_apiê°€ Trueì¸ ê²½ìš°)
        if use_api:
            minute_data = self.get_minute_data_from_api(stock_code, date_str)
            if minute_data is not None:
                # ìºì‹œì— ì €ì¥
                self._save_minute_data_to_cache(stock_code, date_str, minute_data)
                return minute_data

        self.logger.warning(f"ë¶„ë´‰ ë°ì´í„° ì—†ìŒ: {stock_code} {date_str}")
        return None

    def _save_daily_data_to_cache(self, stock_code: str, date_str: str, data: pd.DataFrame):
        """ì¼ë´‰ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥ (ìƒˆë¡œìš´ êµ¬ì¡°: ì¢…ëª©ë³„ í†µí•© íŒŒì¼ ì—…ë°ì´íŠ¸)"""
        try:
            cache_file = self.daily_cache_dir / f"{stock_code}_daily.pkl"
            cache_file.parent.mkdir(parents=True, exist_ok=True)

            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing_data = None
            if cache_file.exists():
                try:
                    with open(cache_file, 'rb') as f:
                        existing_data = pickle.load(f)
                except:
                    existing_data = None

            # ìƒˆ ë°ì´í„°ì— ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€
            if 'date' not in data.columns:
                data = data.copy()
                data['date'] = date_str

            if existing_data is not None and isinstance(existing_data, pd.DataFrame):
                # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                # ê°™ì€ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ìƒˆ ë°ì´í„°ë¡œ êµì²´
                if 'date' in existing_data.columns:
                    existing_data = existing_data[existing_data['date'] != date_str]

                # ìƒˆ ë°ì´í„°ì™€ ë³‘í•©
                combined_data = pd.concat([existing_data, data], ignore_index=True)
                # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
                if 'date' in combined_data.columns:
                    combined_data = combined_data.sort_values('date')
            else:
                combined_data = data

            # í†µí•©ëœ ë°ì´í„° ì €ì¥
            with open(cache_file, 'wb') as f:
                pickle.dump(combined_data, f)

            self.logger.debug(f"ì¼ë´‰ ë°ì´í„° ìºì‹œ ì €ì¥: {stock_code} {date_str} (ì´ {len(combined_data)}ê±´)")

        except Exception as e:
            self.logger.error(f"ì¼ë´‰ ë°ì´í„° ìºì‹œ ì €ì¥ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")

    def _save_minute_data_to_cache(self, stock_code: str, date_str: str, data: pd.DataFrame):
        """ë¶„ë´‰ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        try:
            cache_file = self.minute_cache_dir / f"{stock_code}_{date_str}.pkl"
            cache_file.parent.mkdir(parents=True, exist_ok=True)

            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)

            self.logger.debug(f"ë¶„ë´‰ ë°ì´í„° ìºì‹œ ì €ì¥: {stock_code} {date_str}")

        except Exception as e:
            self.logger.error(f"ë¶„ë´‰ ë°ì´í„° ìºì‹œ ì €ì¥ ì‹¤íŒ¨ ({stock_code}, {date_str}): {e}")

    def collect_analysis_data(self, start_date: str, end_date: str, use_api: bool = True) -> Dict[str, Any]:
        """
        ë¶„ì„ìš© ë°ì´í„° ìˆ˜ì§‘ (ë©”ì¸ í•¨ìˆ˜)

        Args:
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
            use_api: API ì‚¬ìš© ì—¬ë¶€

        Returns:
            Dict: ìˆ˜ì§‘ëœ ë°ì´í„° ì •ë³´
            {
                'candidate_stocks': í›„ë³´ ì¢…ëª© ë°ì´í„°,
                'daily_data': {ì¢…ëª©ì½”ë“œ: {ë‚ ì§œ: ì¼ë´‰ë°ì´í„°}},
                'minute_data': {ì¢…ëª©ì½”ë“œ: {ë‚ ì§œ: ë¶„ë´‰ë°ì´í„°}},
                'collection_stats': ìˆ˜ì§‘ í†µê³„
            }
        """
        self.logger.info(f"ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")

        # API ì‚¬ìš© ì‹œ ì¸ì¦ ì´ˆê¸°í™”
        if use_api:
            if not self._ensure_api_initialized():
                self.logger.warning("API ì¸ì¦ ì‹¤íŒ¨ë¡œ API ì‚¬ìš© ë¶ˆê°€. ìºì‹œ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                use_api = False

        # 1. í›„ë³´ ì¢…ëª© ì¡°íšŒ
        candidate_stocks = self.get_candidate_stocks_by_date_range(start_date, end_date)

        if candidate_stocks.empty:
            self.logger.warning("í›„ë³´ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {
                'candidate_stocks': candidate_stocks,
                'daily_data': {},
                'minute_data': {},
                'collection_stats': {'total_candidates': 0, 'success_daily': 0, 'success_minute': 0}
            }

        # 2. ê° ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜ì§‘
        daily_data = {}
        minute_data = {}
        success_daily = 0
        success_minute = 0

        # ë‚ ì§œ ë²”ìœ„ ìƒì„±
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        date_range = [(start_dt + timedelta(days=i)).strftime('%Y%m%d')
                        for i in range((end_dt - start_dt).days + 1)]

        total_combinations = len(candidate_stocks) * len(date_range)
        processed = 0

        for _, stock in candidate_stocks.iterrows():
            stock_code = stock['stock_code']
            stock_name = stock['stock_name']

            self.logger.info(f"ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘: {stock_code}({stock_name})")

            daily_data[stock_code] = {}
            minute_data[stock_code] = {}

            for date_str in date_range:
                processed += 1
                progress = (processed / total_combinations) * 100

                self.logger.info(f"  ì§„í–‰ë¥ : {progress:.1f}% - {date_str}")

                # ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
                daily_df = self.get_daily_data(stock_code, date_str, use_api)
                if daily_df is not None:
                    daily_data[stock_code][date_str] = daily_df
                    success_daily += 1

                # ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘
                minute_df = self.get_minute_data(stock_code, date_str, use_api)
                if minute_df is not None:
                    minute_data[stock_code][date_str] = minute_df
                    success_minute += 1

        # 3. ìˆ˜ì§‘ í†µê³„
        collection_stats = {
            'total_candidates': len(candidate_stocks),
            'total_dates': len(date_range),
            'total_combinations': total_combinations,
            'success_daily': success_daily,
            'success_minute': success_minute,
            'daily_success_rate': (success_daily / total_combinations) * 100 if total_combinations > 0 else 0,
            'minute_success_rate': (success_minute / total_combinations) * 100 if total_combinations > 0 else 0
        }

        self.logger.info(f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ:")
        self.logger.info(f"  í›„ë³´ ì¢…ëª©: {collection_stats['total_candidates']}ê°œ")
        self.logger.info(f"  ë‚ ì§œ ë²”ìœ„: {len(date_range)}ì¼")
        self.logger.info(f"  ì¼ë´‰ ì„±ê³µ: {success_daily}/{total_combinations} ({collection_stats['daily_success_rate']:.1f}%)")
        self.logger.info(f"  ë¶„ë´‰ ì„±ê³µ: {success_minute}/{total_combinations} ({collection_stats['minute_success_rate']:.1f}%)")

        return {
            'candidate_stocks': candidate_stocks,
            'daily_data': daily_data,
            'minute_data': minute_data,
            'collection_stats': collection_stats
        }


# ì „ì—­ í•¨ìˆ˜ë“¤ (ë©”ì¸ í”„ë¡œê·¸ë¨ì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)
def ensure_stock_data_sufficiency(stock_code: str, date_str: str = None, required_minute_count: int = 15, use_api: bool = True) -> bool:
    """
    ì¢…ëª© ë°ì´í„° ì¶©ë¶„ì„± í™•ì¸ ë° í•„ìš”ì‹œ ì „ì²´ ìˆ˜ì§‘ (ì „ì—­ í•¨ìˆ˜)

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        date_str: ë‚ ì§œ (YYYYMMDD), Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
        required_minute_count: í•„ìš”í•œ ìµœì†Œ ë¶„ë´‰ ê°œìˆ˜
        use_api: API ì‚¬ìš© ì—¬ë¶€

    Returns:
        bool: ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
    """
    if date_str is None:
        date_str = now_kst().strftime('%Y%m%d')

    collector = AnalysisDataCollector()
    return collector.ensure_sufficient_data(stock_code, date_str, required_minute_count, use_api)


def collect_stock_data_if_needed(stock_code: str, date_str: str = None, required_minute_count: int = 15, use_api: bool = True) -> bool:
    """
    ì¢…ëª© ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ìˆ˜ì§‘ (ì „ì—­ í•¨ìˆ˜)

    Args:
        stock_code: ì¢…ëª©ì½”ë“œ
        date_str: ë‚ ì§œ (YYYYMMDD), Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ
        required_minute_count: í•„ìš”í•œ ìµœì†Œ ë¶„ë´‰ ê°œìˆ˜
        use_api: API ì‚¬ìš© ì—¬ë¶€

    Returns:
        bool: ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ ì—¬ë¶€
    """
    return ensure_stock_data_sufficiency(stock_code, date_str, required_minute_count, use_api)


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    collector = AnalysisDataCollector()

    # í…ŒìŠ¤íŠ¸ ë‚ ì§œ ë²”ìœ„ (ìµœê·¼ 7ì¼)
    end_date = now_kst().strftime('%Y-%m-%d')
    start_date = (now_kst() - timedelta(days=7)).strftime('%Y-%m-%d')

    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘: {start_date} ~ {end_date}")

    # ë°ì´í„° ìˆ˜ì§‘
    result = collector.collect_analysis_data(start_date, end_date, use_api=False)  # API ì‚¬ìš© ì•ˆí•¨ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

    print(f"\nìˆ˜ì§‘ ê²°ê³¼:")
    print(f"  í›„ë³´ ì¢…ëª©: {len(result['candidate_stocks'])}ê°œ")
    print(f"  ì¼ë´‰ ë°ì´í„°: {result['collection_stats']['success_daily']}ê±´")
    print(f"  ë¶„ë´‰ ë°ì´í„°: {result['collection_stats']['success_minute']}ê±´")


if __name__ == "__main__":
    main()
